{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yang\\.conda\\envs\\test_speedcom\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataUtils import DataUtils as utils\n",
    "from model_utils import ModelUtils as mutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, Conv1D, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('temp_cfprint.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>name_smiles</th>\n",
       "      <th>Wavelength</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Quantum Yield</th>\n",
       "      <th>cfp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Benzene</td>\n",
       "      <td>C1=CC=CC=C1</td>\n",
       "      <td>254.75</td>\n",
       "      <td>210</td>\n",
       "      <td>0.053</td>\n",
       "      <td>[224, 255, 255, 255, 0, 8, 0, 0, 3, 0, 0, 0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Toluene</td>\n",
       "      <td>CC1=CC=CC=C1</td>\n",
       "      <td>261.75</td>\n",
       "      <td>2860</td>\n",
       "      <td>0.170</td>\n",
       "      <td>[224, 255, 255, 255, 0, 8, 0, 0, 11, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>o-Xylene</td>\n",
       "      <td>CC1=CC=CC=C1C</td>\n",
       "      <td>263.00</td>\n",
       "      <td>254</td>\n",
       "      <td>0.170</td>\n",
       "      <td>[224, 255, 255, 255, 0, 8, 0, 0, 10, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>m-Xylene</td>\n",
       "      <td>CC1=CC(=CC=C1)C</td>\n",
       "      <td>265.00</td>\n",
       "      <td>284</td>\n",
       "      <td>0.130</td>\n",
       "      <td>[224, 255, 255, 255, 0, 8, 0, 0, 12, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>p-Xylene</td>\n",
       "      <td>CC1=CC=C(C=C1)C</td>\n",
       "      <td>275.00</td>\n",
       "      <td>770</td>\n",
       "      <td>0.220</td>\n",
       "      <td>[224, 255, 255, 255, 0, 8, 0, 0, 8, 0, 0, 0, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #      Name      name_smiles  Wavelength  Epsilon  Quantum Yield  \\\n",
       "0  1   Benzene      C1=CC=CC=C1      254.75      210          0.053   \n",
       "1  2   Toluene     CC1=CC=CC=C1      261.75     2860          0.170   \n",
       "2  3  o-Xylene    CC1=CC=CC=C1C      263.00      254          0.170   \n",
       "3  4  m-Xylene  CC1=CC(=CC=C1)C      265.00      284          0.130   \n",
       "4  5  p-Xylene  CC1=CC=C(C=C1)C      275.00      770          0.220   \n",
       "\n",
       "                                                 cfp  \n",
       "0  [224, 255, 255, 255, 0, 8, 0, 0, 3, 0, 0, 0, 2...  \n",
       "1  [224, 255, 255, 255, 0, 8, 0, 0, 11, 0, 0, 0, ...  \n",
       "2  [224, 255, 255, 255, 0, 8, 0, 0, 10, 0, 0, 0, ...  \n",
       "3  [224, 255, 255, 255, 0, 8, 0, 0, 12, 0, 0, 0, ...  \n",
       "4  [224, 255, 255, 255, 0, 8, 0, 0, 8, 0, 0, 0, 1...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fingerprint column shape is (267, 137)\n"
     ]
    }
   ],
   "source": [
    "X_fp=utils.finger_print_clean(df=df,colname_string_array='cfp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 137)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.values[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model original Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cat = mutls.combine_columns((X_fp, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = d_cat[:,0:-1], d_cat[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([254.75, 261.75, 263.0, 265.0, 275.0, 265.0, 278.0, 271.0, 271.0,\n",
       "       270.75, 220.0, 222.0, 242.0, 227.0, 241.0, 288.0, 251.0, 279.0,\n",
       "       265.0, 228.0, 258.0, 248.0, 236.0, 274.0, 277.0, 227.0, 222.0,\n",
       "       218.0, 310.25, 291.0, 240.0, 251.0, 263.0, 245.0, 302.0, 252.0,\n",
       "       283.0, 225.0, 316.0, 230.0, 442.0, 247.5, 276.25, 294.75, 312.0,\n",
       "       251.0, 206.0, 209.0, 212.0, 245.0, 223.0, 278.0, 275.0, 356.25,\n",
       "       475.0, 578.0, 252.0, 241.0, 258.0, 372.5, 270.25, 303.0, 228.0,\n",
       "       239.0, 245.0, 218.0, 227.0, 235.0, 278.75, 276.0, 293.75, 326.0,\n",
       "       330.0, 353.25, 432.25, 425.0, 372.0, 451.0, 251.0, 276.0, 227.0,\n",
       "       257.0, 265.0, 270.0, 215.0, 281.0, 238.0, 204.0, 219.0, 245.0,\n",
       "       217.0, 253.0, 231.75, 206.0, 278.0, 502.0, 413.0, 286.0, 336.0,\n",
       "       460.5, 219.0, 413.0, 247.0, 349.0, 262.0, 257.5, 274.25, 211.0,\n",
       "       278.0, 261.0, 243.0, 266.75, 263.75, 258.25, 228.0, 259.0, 212.0,\n",
       "       263.0, 265.0, 206.0, 248.0, 281.0, 239.75, 225.0, 288.0, 211.0,\n",
       "       270.0, 287.0, 458.0, 243.0, 258.0, 267.0, 401.0, 246.0, 280.0,\n",
       "       251.0, 268.0, 249.0, 251.25, 248.0, 250.0, 233.0, 296.0, 303.0,\n",
       "       275.0, 280.0, 326.0, 338.0, 323.75, 373.25, 459.25, 436.0, 407.5,\n",
       "       384.0, 436.0, 444.75, 361.0, 278.0, 247.0, 261.0, 270.5, 264.0,\n",
       "       249.0, 248.0, 533.0, 278.0, 587.0, 253.0, 605.0, 656.0, 654.0,\n",
       "       628.0, 237.0, 239.0, 642.5, 603.0, 519.4, 627.5, 319.0, 430.0,\n",
       "       466.0, 478.0, 486.0, 503.0, 481.0, 498.0, 555.0, 530.0, 512.0,\n",
       "       563.0, 504.0, 518.0, 619.0, 513.0, 483.0, 497.0, 606.0, 524.25,\n",
       "       603.5, 711.0, 592.0, 709.5, 818.0, 485.0, 582.0, 687.5, 544.25,\n",
       "       789.0, 559.25, 655.75, 763.25, 559.5, 431.25, 616.5, 590.5, 543.0,\n",
       "       590.0, 554.0, 558.0, 573.0, 597.0, 435.75, 500.25, 502.0, 535.0,\n",
       "       559.0, 261.0, 511.75, 542.75, 553.0, 529.75, 565.0, 576.0, 338.5,\n",
       "       279.75, 325.0, 249.0, 285.0, 345.5, 627.25, 276.0, 424.0, 205.0,\n",
       "       203.0, 208.0, 396.25, 402.0, 409.75, 408.0, 385.9, 429.0, 491.0,\n",
       "       450.75, 377.0, 361.0, 698.5, 674.0, 674.0, 569.0, 429.0, 453.0,\n",
       "       410.0, 413.0, 414.0, 401.0, 413.0, 780.2], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = utils.splitData(X, y, ratio=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_int_counts = len(np.unique(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
       "       53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
       "       70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 88, 89, 90,\n",
       "       92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 106, 108, 109,\n",
       "       110, 112, 113, 114, 116, 117, 118, 120, 121, 122, 124, 125, 126,\n",
       "       128, 129, 130, 132, 133, 134, 136, 137, 138, 140, 141, 142, 144,\n",
       "       145, 146, 148, 149, 150, 152, 153, 154, 156, 157, 158, 160, 161,\n",
       "       162, 164, 165, 166, 168, 169, 170, 172, 173, 174, 176, 177, 178,\n",
       "       180, 181, 182, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196,\n",
       "       197, 198, 200, 201, 202, 204, 205, 206, 208, 209, 210, 212, 213,\n",
       "       214, 216, 217, 218, 220, 221, 222, 224, 225, 226, 228, 229, 230,\n",
       "       232, 233, 234, 236, 237, 238, 240, 241, 242, 244, 245, 246, 248,\n",
       "       249, 250, 252, 253, 254, 255], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_int_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 137)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(256, hidden_size, input_length= X.shape[1]))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(hidden_size, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 137, 50)           12800     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 137, 50)           20200     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 137, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 137, 50)           20200     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 137, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 137, 50)           20200     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 137, 50)           0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 137, 50)           2550      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6850)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 6851      \n",
      "=================================================================\n",
      "Total params: 82,801\n",
      "Trainable params: 82,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer='Adam', metrics=['mean_absolute_error'])\n",
    "model.summary() ##use mean_squared_error loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 213 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "213/213 [==============================] - 8s 39ms/step - loss: 371.4458 - mean_absolute_error: 371.4458 - val_loss: 345.9026 - val_mean_absolute_error: 345.9026\n",
      "Epoch 2/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 364.7319 - mean_absolute_error: 364.7319 - val_loss: 324.5455 - val_mean_absolute_error: 324.5455\n",
      "Epoch 3/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 319.5907 - mean_absolute_error: 319.5907 - val_loss: 254.3188 - val_mean_absolute_error: 254.3188\n",
      "Epoch 4/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 224.9882 - mean_absolute_error: 224.9882 - val_loss: 122.8426 - val_mean_absolute_error: 122.8426\n",
      "Epoch 5/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 128.0332 - mean_absolute_error: 128.0332 - val_loss: 117.9687 - val_mean_absolute_error: 117.9687\n",
      "Epoch 6/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 135.6477 - mean_absolute_error: 135.6477 - val_loss: 120.8935 - val_mean_absolute_error: 120.8935\n",
      "Epoch 7/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 130.8058 - mean_absolute_error: 130.8058 - val_loss: 102.9388 - val_mean_absolute_error: 102.9388\n",
      "Epoch 8/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 122.0963 - mean_absolute_error: 122.0963 - val_loss: 98.5865 - val_mean_absolute_error: 98.5865\n",
      "Epoch 9/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 122.4627 - mean_absolute_error: 122.4627 - val_loss: 98.3759 - val_mean_absolute_error: 98.3759\n",
      "Epoch 10/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.4872 - mean_absolute_error: 121.4872 - val_loss: 97.8441 - val_mean_absolute_error: 97.8441\n",
      "Epoch 11/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6316 - mean_absolute_error: 121.6316 - val_loss: 98.3015 - val_mean_absolute_error: 98.3015\n",
      "Epoch 12/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.3454 - mean_absolute_error: 121.3454 - val_loss: 97.7627 - val_mean_absolute_error: 97.7627\n",
      "Epoch 13/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.7445 - mean_absolute_error: 121.7445 - val_loss: 97.8171 - val_mean_absolute_error: 97.8171\n",
      "Epoch 14/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 122.0747 - mean_absolute_error: 122.0747 - val_loss: 98.0556 - val_mean_absolute_error: 98.0556\n",
      "Epoch 15/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.5217 - mean_absolute_error: 121.5217 - val_loss: 98.6075 - val_mean_absolute_error: 98.6075\n",
      "Epoch 16/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.4832 - mean_absolute_error: 121.4832 - val_loss: 97.7184 - val_mean_absolute_error: 97.7184\n",
      "Epoch 17/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6566 - mean_absolute_error: 121.6566 - val_loss: 98.1235 - val_mean_absolute_error: 98.1235\n",
      "Epoch 18/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.4026 - mean_absolute_error: 121.4026 - val_loss: 98.0163 - val_mean_absolute_error: 98.0163\n",
      "Epoch 19/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.3978 - mean_absolute_error: 121.3978 - val_loss: 98.0776 - val_mean_absolute_error: 98.0776\n",
      "Epoch 20/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.0411 - mean_absolute_error: 121.0411 - val_loss: 97.7742 - val_mean_absolute_error: 97.7742\n",
      "Epoch 21/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.8485 - mean_absolute_error: 121.8485 - val_loss: 97.7185 - val_mean_absolute_error: 97.7185\n",
      "Epoch 22/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6155 - mean_absolute_error: 121.6155 - val_loss: 98.0619 - val_mean_absolute_error: 98.0619\n",
      "Epoch 23/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 121.2844 - mean_absolute_error: 121.2844 - val_loss: 97.7185 - val_mean_absolute_error: 97.7185\n",
      "Epoch 24/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6319 - mean_absolute_error: 121.6319 - val_loss: 97.7385 - val_mean_absolute_error: 97.7385\n",
      "Epoch 25/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6323 - mean_absolute_error: 121.6323 - val_loss: 98.7860 - val_mean_absolute_error: 98.7860\n",
      "Epoch 26/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6417 - mean_absolute_error: 121.6417 - val_loss: 98.1139 - val_mean_absolute_error: 98.1139\n",
      "Epoch 27/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6420 - mean_absolute_error: 121.6420 - val_loss: 97.8394 - val_mean_absolute_error: 97.8394\n",
      "Epoch 28/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6085 - mean_absolute_error: 121.6085 - val_loss: 97.7322 - val_mean_absolute_error: 97.7322\n",
      "Epoch 29/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.3799 - mean_absolute_error: 121.3799 - val_loss: 98.1090 - val_mean_absolute_error: 98.1090\n",
      "Epoch 30/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.9610 - mean_absolute_error: 121.9610 - val_loss: 98.0709 - val_mean_absolute_error: 98.0709\n",
      "Epoch 31/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6249 - mean_absolute_error: 121.6249 - val_loss: 98.1922 - val_mean_absolute_error: 98.1922\n",
      "Epoch 32/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.7192 - mean_absolute_error: 121.7192 - val_loss: 98.0283 - val_mean_absolute_error: 98.0283\n",
      "Epoch 33/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.8473 - mean_absolute_error: 121.8473 - val_loss: 97.9622 - val_mean_absolute_error: 97.9622\n",
      "Epoch 34/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6244 - mean_absolute_error: 121.6244 - val_loss: 97.7184 - val_mean_absolute_error: 97.7184\n",
      "Epoch 35/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 122.2843 - mean_absolute_error: 122.2843 - val_loss: 98.9508 - val_mean_absolute_error: 98.9508\n",
      "Epoch 36/100\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 121.8127 - mean_absolute_error: 121.8127 - val_loss: 98.6365 - val_mean_absolute_error: 98.6365\n",
      "Epoch 37/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 122.6051 - mean_absolute_error: 122.6051 - val_loss: 98.2862 - val_mean_absolute_error: 98.2862\n",
      "Epoch 38/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.4705 - mean_absolute_error: 121.4705 - val_loss: 97.8544 - val_mean_absolute_error: 97.8544\n",
      "Epoch 39/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.1339 - mean_absolute_error: 122.1339 - val_loss: 98.2449 - val_mean_absolute_error: 98.2449\n",
      "Epoch 40/100\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 121.8070 - mean_absolute_error: 121.8070 - val_loss: 98.0316 - val_mean_absolute_error: 98.0316\n",
      "Epoch 41/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.5880 - mean_absolute_error: 121.5880 - val_loss: 99.7299 - val_mean_absolute_error: 99.7299\n",
      "Epoch 42/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 122.1959 - mean_absolute_error: 122.1959 - val_loss: 99.4452 - val_mean_absolute_error: 99.4452\n",
      "Epoch 43/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.2821 - mean_absolute_error: 121.2821 - val_loss: 98.0207 - val_mean_absolute_error: 98.0207\n",
      "Epoch 44/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.3639 - mean_absolute_error: 122.3639 - val_loss: 98.1360 - val_mean_absolute_error: 98.1360\n",
      "Epoch 45/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 122.0737 - mean_absolute_error: 122.0737 - val_loss: 98.8063 - val_mean_absolute_error: 98.8063\n",
      "Epoch 46/100\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 121.8226 - mean_absolute_error: 121.8226 - val_loss: 98.8102 - val_mean_absolute_error: 98.8102\n",
      "Epoch 47/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.7224 - mean_absolute_error: 121.7224 - val_loss: 98.8268 - val_mean_absolute_error: 98.8268\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 3s 12ms/step - loss: 121.3199 - mean_absolute_error: 121.3199 - val_loss: 98.6252 - val_mean_absolute_error: 98.6252\n",
      "Epoch 49/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.9260 - mean_absolute_error: 121.9260 - val_loss: 98.8133 - val_mean_absolute_error: 98.8133\n",
      "Epoch 50/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.4556 - mean_absolute_error: 121.4556 - val_loss: 97.7175 - val_mean_absolute_error: 97.7175\n",
      "Epoch 51/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.1086 - mean_absolute_error: 122.1086 - val_loss: 98.0477 - val_mean_absolute_error: 98.0477\n",
      "Epoch 52/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.2317 - mean_absolute_error: 122.2317 - val_loss: 99.6527 - val_mean_absolute_error: 99.6527\n",
      "Epoch 53/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.2493 - mean_absolute_error: 122.2493 - val_loss: 99.6112 - val_mean_absolute_error: 99.6112\n",
      "Epoch 54/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.9163 - mean_absolute_error: 121.9163 - val_loss: 97.7175 - val_mean_absolute_error: 97.7175\n",
      "Epoch 55/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.3685 - mean_absolute_error: 121.3685 - val_loss: 97.7903 - val_mean_absolute_error: 97.7903\n",
      "Epoch 56/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6223 - mean_absolute_error: 121.6223 - val_loss: 97.7637 - val_mean_absolute_error: 97.7637\n",
      "Epoch 57/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.1821 - mean_absolute_error: 121.1821 - val_loss: 97.7175 - val_mean_absolute_error: 97.7175\n",
      "Epoch 58/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.7275 - mean_absolute_error: 121.7275 - val_loss: 98.0315 - val_mean_absolute_error: 98.0315\n",
      "Epoch 59/100\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 121.2905 - mean_absolute_error: 121.2905 - val_loss: 98.3025 - val_mean_absolute_error: 98.3025\n",
      "Epoch 60/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 122.3423 - mean_absolute_error: 122.3423 - val_loss: 97.7700 - val_mean_absolute_error: 97.7700\n",
      "Epoch 61/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.7958 - mean_absolute_error: 121.7958 - val_loss: 101.0486 - val_mean_absolute_error: 101.0486\n",
      "Epoch 62/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.4058 - mean_absolute_error: 122.4058 - val_loss: 98.6909 - val_mean_absolute_error: 98.6909\n",
      "Epoch 63/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.5790 - mean_absolute_error: 122.5790 - val_loss: 97.7174 - val_mean_absolute_error: 97.7174\n",
      "Epoch 64/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 123.6901 - mean_absolute_error: 123.6901 - val_loss: 100.7722 - val_mean_absolute_error: 100.7722\n",
      "Epoch 65/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.7461 - mean_absolute_error: 121.7461 - val_loss: 98.7317 - val_mean_absolute_error: 98.7317\n",
      "Epoch 66/100\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 121.5830 - mean_absolute_error: 121.5830 - val_loss: 98.0829 - val_mean_absolute_error: 98.0829\n",
      "Epoch 67/100\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 122.3411 - mean_absolute_error: 122.3411 - val_loss: 97.7173 - val_mean_absolute_error: 97.7173\n",
      "Epoch 68/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.7131 - mean_absolute_error: 121.7131 - val_loss: 97.8331 - val_mean_absolute_error: 97.8331\n",
      "Epoch 69/100\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 121.9925 - mean_absolute_error: 121.9925 - val_loss: 98.4798 - val_mean_absolute_error: 98.4798\n",
      "Epoch 70/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.8010 - mean_absolute_error: 121.8010 - val_loss: 97.7173 - val_mean_absolute_error: 97.7173\n",
      "Epoch 71/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.5579 - mean_absolute_error: 121.5579 - val_loss: 97.9710 - val_mean_absolute_error: 97.9710\n",
      "Epoch 72/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.8215 - mean_absolute_error: 121.8215 - val_loss: 97.7868 - val_mean_absolute_error: 97.7868\n",
      "Epoch 73/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.9322 - mean_absolute_error: 121.9322 - val_loss: 98.2639 - val_mean_absolute_error: 98.2639\n",
      "Epoch 74/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.5369 - mean_absolute_error: 121.5369 - val_loss: 98.2024 - val_mean_absolute_error: 98.2024\n",
      "Epoch 75/100\n",
      "213/213 [==============================] - 3s 13ms/step - loss: 122.0019 - mean_absolute_error: 122.0019 - val_loss: 97.7172 - val_mean_absolute_error: 97.7172\n",
      "Epoch 76/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.4548 - mean_absolute_error: 121.4548 - val_loss: 98.4978 - val_mean_absolute_error: 98.4978\n",
      "Epoch 77/100\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 121.6153 - mean_absolute_error: 121.6153 - val_loss: 98.1053 - val_mean_absolute_error: 98.1053\n",
      "Epoch 78/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.0847 - mean_absolute_error: 122.0847 - val_loss: 97.8653 - val_mean_absolute_error: 97.8653\n",
      "Epoch 79/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.7322 - mean_absolute_error: 121.7322 - val_loss: 97.7171 - val_mean_absolute_error: 97.7171\n",
      "Epoch 80/100\n",
      "213/213 [==============================] - 3s 13ms/step - loss: 122.6023 - mean_absolute_error: 122.6023 - val_loss: 97.9079 - val_mean_absolute_error: 97.9079\n",
      "Epoch 81/100\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 122.0953 - mean_absolute_error: 122.0953 - val_loss: 99.6893 - val_mean_absolute_error: 99.6893\n",
      "Epoch 82/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.8800 - mean_absolute_error: 121.8800 - val_loss: 98.2308 - val_mean_absolute_error: 98.2308\n",
      "Epoch 83/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.3768 - mean_absolute_error: 121.3768 - val_loss: 98.0845 - val_mean_absolute_error: 98.0845\n",
      "Epoch 84/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.4189 - mean_absolute_error: 121.4189 - val_loss: 97.7169 - val_mean_absolute_error: 97.7169\n",
      "Epoch 85/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.5284 - mean_absolute_error: 121.5284 - val_loss: 97.7168 - val_mean_absolute_error: 97.7168\n",
      "Epoch 86/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.3678 - mean_absolute_error: 121.3678 - val_loss: 97.7167 - val_mean_absolute_error: 97.7167\n",
      "Epoch 87/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.3449 - mean_absolute_error: 122.3449 - val_loss: 97.8176 - val_mean_absolute_error: 97.8176\n",
      "Epoch 88/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 121.6637 - mean_absolute_error: 121.6637 - val_loss: 98.9107 - val_mean_absolute_error: 98.9107\n",
      "Epoch 89/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.5893 - mean_absolute_error: 121.5893 - val_loss: 98.5250 - val_mean_absolute_error: 98.5250\n",
      "Epoch 90/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.6812 - mean_absolute_error: 121.6812 - val_loss: 97.7159 - val_mean_absolute_error: 97.7159\n",
      "Epoch 91/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.2285 - mean_absolute_error: 122.2285 - val_loss: 97.8259 - val_mean_absolute_error: 97.8259\n",
      "Epoch 92/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.6149 - mean_absolute_error: 121.6149 - val_loss: 97.7138 - val_mean_absolute_error: 97.7138\n",
      "Epoch 93/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.2476 - mean_absolute_error: 122.2476 - val_loss: 98.9372 - val_mean_absolute_error: 98.9372\n",
      "Epoch 94/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 122.6338 - mean_absolute_error: 122.6338 - val_loss: 98.8344 - val_mean_absolute_error: 98.8344\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 3s 12ms/step - loss: 121.3471 - mean_absolute_error: 121.3471 - val_loss: 98.1443 - val_mean_absolute_error: 98.1443\n",
      "Epoch 96/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.7032 - mean_absolute_error: 121.7032 - val_loss: 97.7915 - val_mean_absolute_error: 97.7915\n",
      "Epoch 97/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.7464 - mean_absolute_error: 121.7464 - val_loss: 99.2007 - val_mean_absolute_error: 99.2007\n",
      "Epoch 98/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.5803 - mean_absolute_error: 121.5803 - val_loss: 98.9213 - val_mean_absolute_error: 98.9213\n",
      "Epoch 99/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.5795 - mean_absolute_error: 121.5795 - val_loss: 97.7123 - val_mean_absolute_error: 97.7123\n",
      "Epoch 100/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 121.5818 - mean_absolute_error: 121.5818 - val_loss: 97.7098 - val_mean_absolute_error: 97.7098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202686ab4a8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First model2, change loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 137, 50)           12800     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 137, 50)           20200     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 137, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 137, 50)           20200     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 137, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 137, 50)           20200     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 137, 50)           0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 137, 50)           2550      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6850)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 6851      \n",
      "=================================================================\n",
      "Total params: 82,801\n",
      "Trainable params: 82,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mean_absolute_error'])\n",
    "model.summary() ##use mean_squared_error loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 213 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "213/213 [==============================] - 8s 36ms/step - loss: 160529.8939 - mean_absolute_error: 371.5190 - val_loss: 135713.5061 - val_mean_absolute_error: 346.2331\n",
      "Epoch 2/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 156974.6131 - mean_absolute_error: 366.6921 - val_loss: 123406.2170 - val_mean_absolute_error: 327.8209\n",
      "Epoch 3/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 122958.3816 - mean_absolute_error: 317.8396 - val_loss: 75039.2554 - val_mean_absolute_error: 243.2930\n",
      "Epoch 4/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 68738.3347 - mean_absolute_error: 210.6747 - val_loss: 25942.1020 - val_mean_absolute_error: 108.0121\n",
      "Epoch 5/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 26648.6717 - mean_absolute_error: 128.1343 - val_loss: 21565.3057 - val_mean_absolute_error: 132.3983\n",
      "Epoch 6/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 28573.6119 - mean_absolute_error: 151.3210 - val_loss: 23331.2107 - val_mean_absolute_error: 137.3990\n",
      "Epoch 7/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 25208.7650 - mean_absolute_error: 141.5184 - val_loss: 15996.6209 - val_mean_absolute_error: 112.3074\n",
      "Epoch 8/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22997.8944 - mean_absolute_error: 126.4401 - val_loss: 16034.4159 - val_mean_absolute_error: 106.0241\n",
      "Epoch 9/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 23173.7894 - mean_absolute_error: 124.8821 - val_loss: 15833.5039 - val_mean_absolute_error: 109.5407\n",
      "Epoch 10/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22374.8275 - mean_absolute_error: 127.6233 - val_loss: 16412.4069 - val_mean_absolute_error: 115.6067\n",
      "Epoch 11/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22846.1138 - mean_absolute_error: 132.3754 - val_loss: 16771.9849 - val_mean_absolute_error: 117.5514\n",
      "Epoch 12/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22913.4478 - mean_absolute_error: 131.2525 - val_loss: 16010.9709 - val_mean_absolute_error: 112.4490\n",
      "Epoch 13/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22557.5275 - mean_absolute_error: 129.2747 - val_loss: 16080.6152 - val_mean_absolute_error: 113.1433\n",
      "Epoch 14/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22528.0077 - mean_absolute_error: 128.8507 - val_loss: 15989.0543 - val_mean_absolute_error: 112.2303\n",
      "Epoch 15/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22499.0866 - mean_absolute_error: 128.2703 - val_loss: 15970.7059 - val_mean_absolute_error: 112.0352\n",
      "Epoch 16/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 23101.8411 - mean_absolute_error: 132.2956 - val_loss: 16748.7973 - val_mean_absolute_error: 117.4387\n",
      "Epoch 17/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22494.3456 - mean_absolute_error: 130.3351 - val_loss: 16003.4599 - val_mean_absolute_error: 112.3756\n",
      "Epoch 18/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22408.3249 - mean_absolute_error: 128.1591 - val_loss: 15936.8239 - val_mean_absolute_error: 111.6377\n",
      "Epoch 19/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22564.2174 - mean_absolute_error: 128.5118 - val_loss: 16104.6829 - val_mean_absolute_error: 113.3638\n",
      "Epoch 20/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22562.8426 - mean_absolute_error: 128.4960 - val_loss: 15963.1608 - val_mean_absolute_error: 111.9513\n",
      "Epoch 21/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22695.5555 - mean_absolute_error: 129.7794 - val_loss: 16203.0569 - val_mean_absolute_error: 114.1774\n",
      "Epoch 22/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22585.5405 - mean_absolute_error: 129.6969 - val_loss: 16085.5144 - val_mean_absolute_error: 113.1891\n",
      "Epoch 23/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22592.2386 - mean_absolute_error: 130.2082 - val_loss: 16429.8609 - val_mean_absolute_error: 115.7131\n",
      "Epoch 24/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22725.0331 - mean_absolute_error: 129.9162 - val_loss: 15968.1645 - val_mean_absolute_error: 112.0072\n",
      "Epoch 25/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22629.0616 - mean_absolute_error: 128.7441 - val_loss: 16081.9573 - val_mean_absolute_error: 113.1559\n",
      "Epoch 26/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22576.4935 - mean_absolute_error: 130.1718 - val_loss: 16251.7743 - val_mean_absolute_error: 114.5401\n",
      "Epoch 27/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22502.3937 - mean_absolute_error: 130.0615 - val_loss: 16054.1810 - val_mean_absolute_error: 112.8885\n",
      "Epoch 28/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22653.0941 - mean_absolute_error: 129.2068 - val_loss: 15961.8235 - val_mean_absolute_error: 111.9362\n",
      "Epoch 29/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22643.0311 - mean_absolute_error: 129.5472 - val_loss: 16121.1512 - val_mean_absolute_error: 113.5092\n",
      "Epoch 30/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22593.0180 - mean_absolute_error: 129.5839 - val_loss: 16140.4249 - val_mean_absolute_error: 113.6741\n",
      "Epoch 31/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22618.5174 - mean_absolute_error: 129.1658 - val_loss: 16081.5740 - val_mean_absolute_error: 113.1523\n",
      "Epoch 32/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22560.5812 - mean_absolute_error: 129.7588 - val_loss: 16265.0672 - val_mean_absolute_error: 114.6353\n",
      "Epoch 33/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22694.2838 - mean_absolute_error: 129.7118 - val_loss: 16006.2195 - val_mean_absolute_error: 112.4028\n",
      "Epoch 34/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 22529.4568 - mean_absolute_error: 129.3509 - val_loss: 16136.9752 - val_mean_absolute_error: 113.6450\n",
      "Epoch 35/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22753.5976 - mean_absolute_error: 130.9521 - val_loss: 16365.1689 - val_mean_absolute_error: 115.3103\n",
      "Epoch 36/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22417.5496 - mean_absolute_error: 129.4655 - val_loss: 15998.5684 - val_mean_absolute_error: 112.3270\n",
      "Epoch 37/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22823.8414 - mean_absolute_error: 128.0209 - val_loss: 15873.9244 - val_mean_absolute_error: 110.6691\n",
      "Epoch 38/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22531.9589 - mean_absolute_error: 129.9756 - val_loss: 16691.8634 - val_mean_absolute_error: 117.1558\n",
      "Epoch 39/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22598.5324 - mean_absolute_error: 131.5884 - val_loss: 16252.4866 - val_mean_absolute_error: 114.5453\n",
      "Epoch 40/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22679.6115 - mean_absolute_error: 129.3440 - val_loss: 15916.7986 - val_mean_absolute_error: 111.3723\n",
      "Epoch 41/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22481.8345 - mean_absolute_error: 128.3883 - val_loss: 16096.7714 - val_mean_absolute_error: 113.2926\n",
      "Epoch 42/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22603.6458 - mean_absolute_error: 130.9008 - val_loss: 16434.1985 - val_mean_absolute_error: 115.7394\n",
      "Epoch 43/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22743.9725 - mean_absolute_error: 128.8791 - val_loss: 15878.9984 - val_mean_absolute_error: 110.7669\n",
      "Epoch 44/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22532.1104 - mean_absolute_error: 128.5596 - val_loss: 16364.4439 - val_mean_absolute_error: 115.3057\n",
      "Epoch 45/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22711.0854 - mean_absolute_error: 131.0406 - val_loss: 16169.2973 - val_mean_absolute_error: 113.9120\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 2s 11ms/step - loss: 22338.8572 - mean_absolute_error: 129.0616 - val_loss: 15963.2139 - val_mean_absolute_error: 111.9521\n",
      "Epoch 47/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22764.1123 - mean_absolute_error: 127.8822 - val_loss: 15935.7211 - val_mean_absolute_error: 111.6240\n",
      "Epoch 48/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22610.8333 - mean_absolute_error: 128.9553 - val_loss: 16072.1042 - val_mean_absolute_error: 113.0630\n",
      "Epoch 49/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22427.1392 - mean_absolute_error: 129.0361 - val_loss: 16306.1367 - val_mean_absolute_error: 114.9209\n",
      "Epoch 50/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22540.3139 - mean_absolute_error: 130.4977 - val_loss: 16292.5463 - val_mean_absolute_error: 114.8278\n",
      "Epoch 51/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22646.4158 - mean_absolute_error: 129.1745 - val_loss: 15887.1356 - val_mean_absolute_error: 110.9132\n",
      "Epoch 52/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22681.1281 - mean_absolute_error: 127.4388 - val_loss: 16005.7244 - val_mean_absolute_error: 112.3980\n",
      "Epoch 53/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22640.2612 - mean_absolute_error: 130.9415 - val_loss: 16618.4125 - val_mean_absolute_error: 116.7767\n",
      "Epoch 54/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22544.3035 - mean_absolute_error: 130.1995 - val_loss: 16035.0375 - val_mean_absolute_error: 112.6946\n",
      "Epoch 55/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22660.8053 - mean_absolute_error: 128.6582 - val_loss: 15912.3311 - val_mean_absolute_error: 111.3090\n",
      "Epoch 56/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22629.1596 - mean_absolute_error: 128.7981 - val_loss: 16250.5689 - val_mean_absolute_error: 114.5315\n",
      "Epoch 57/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22713.7824 - mean_absolute_error: 130.9815 - val_loss: 16302.8173 - val_mean_absolute_error: 114.8984\n",
      "Epoch 58/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22560.4154 - mean_absolute_error: 129.3760 - val_loss: 15938.3072 - val_mean_absolute_error: 111.6569\n",
      "Epoch 59/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22585.9594 - mean_absolute_error: 129.3513 - val_loss: 16170.3137 - val_mean_absolute_error: 113.9204\n",
      "Epoch 60/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22473.2928 - mean_absolute_error: 128.7952 - val_loss: 15974.4780 - val_mean_absolute_error: 112.0767\n",
      "Epoch 61/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22539.2130 - mean_absolute_error: 129.5468 - val_loss: 16104.3271 - val_mean_absolute_error: 113.3611\n",
      "Epoch 62/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22670.0556 - mean_absolute_error: 129.8793 - val_loss: 16099.3431 - val_mean_absolute_error: 113.3162\n",
      "Epoch 63/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22531.3882 - mean_absolute_error: 130.3114 - val_loss: 16377.5046 - val_mean_absolute_error: 115.3892\n",
      "Epoch 64/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22564.7896 - mean_absolute_error: 129.7342 - val_loss: 15900.3108 - val_mean_absolute_error: 111.1292\n",
      "Epoch 65/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22738.8882 - mean_absolute_error: 128.6964 - val_loss: 15977.9235 - val_mean_absolute_error: 112.1138\n",
      "Epoch 66/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22692.3970 - mean_absolute_error: 128.5395 - val_loss: 16029.5334 - val_mean_absolute_error: 112.6374\n",
      "Epoch 67/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22330.2846 - mean_absolute_error: 128.9404 - val_loss: 16375.5186 - val_mean_absolute_error: 115.3766\n",
      "Epoch 68/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22717.9303 - mean_absolute_error: 131.4261 - val_loss: 16359.3393 - val_mean_absolute_error: 115.2731\n",
      "Epoch 69/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22554.1082 - mean_absolute_error: 129.8785 - val_loss: 15977.7643 - val_mean_absolute_error: 112.1121\n",
      "Epoch 70/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22458.6974 - mean_absolute_error: 128.0957 - val_loss: 15896.2790 - val_mean_absolute_error: 111.0660\n",
      "Epoch 71/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22658.5032 - mean_absolute_error: 128.4260 - val_loss: 16027.2542 - val_mean_absolute_error: 112.6134\n",
      "Epoch 72/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22739.9383 - mean_absolute_error: 130.9515 - val_loss: 16454.1789 - val_mean_absolute_error: 115.8591\n",
      "Epoch 73/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22661.0785 - mean_absolute_error: 130.3931 - val_loss: 16020.7292 - val_mean_absolute_error: 112.5438\n",
      "Epoch 74/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22604.6135 - mean_absolute_error: 128.3577 - val_loss: 15918.8627 - val_mean_absolute_error: 111.4015\n",
      "Epoch 75/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22579.5722 - mean_absolute_error: 128.6467 - val_loss: 16157.8948 - val_mean_absolute_error: 113.8196\n",
      "Epoch 76/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22467.5516 - mean_absolute_error: 129.2446 - val_loss: 16147.3040 - val_mean_absolute_error: 113.7322\n",
      "Epoch 77/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22513.2949 - mean_absolute_error: 129.5523 - val_loss: 16163.4758 - val_mean_absolute_error: 113.8652\n",
      "Epoch 78/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22624.4313 - mean_absolute_error: 129.6478 - val_loss: 16111.5445 - val_mean_absolute_error: 113.4253\n",
      "Epoch 79/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22535.0987 - mean_absolute_error: 129.3774 - val_loss: 16157.2756 - val_mean_absolute_error: 113.8146\n",
      "Epoch 80/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22704.3194 - mean_absolute_error: 130.9706 - val_loss: 16184.2186 - val_mean_absolute_error: 114.0312\n",
      "Epoch 81/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22496.3015 - mean_absolute_error: 129.0946 - val_loss: 16132.9443 - val_mean_absolute_error: 113.6111\n",
      "Epoch 82/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22551.2107 - mean_absolute_error: 129.9940 - val_loss: 16197.5144 - val_mean_absolute_error: 114.1350\n",
      "Epoch 83/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22585.6208 - mean_absolute_error: 129.4987 - val_loss: 15944.8085 - val_mean_absolute_error: 111.7372\n",
      "Epoch 84/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22563.9506 - mean_absolute_error: 128.0584 - val_loss: 15986.2165 - val_mean_absolute_error: 112.2014\n",
      "Epoch 85/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22656.2753 - mean_absolute_error: 129.3078 - val_loss: 16051.7904 - val_mean_absolute_error: 112.8653\n",
      "Epoch 86/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22763.7710 - mean_absolute_error: 130.2261 - val_loss: 16227.4710 - val_mean_absolute_error: 114.3623\n",
      "Epoch 87/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22676.6264 - mean_absolute_error: 130.3570 - val_loss: 15973.9095 - val_mean_absolute_error: 112.0706\n",
      "Epoch 88/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22563.1161 - mean_absolute_error: 128.3653 - val_loss: 15949.1888 - val_mean_absolute_error: 111.7899\n",
      "Epoch 89/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22815.1300 - mean_absolute_error: 130.9218 - val_loss: 16432.2097 - val_mean_absolute_error: 115.7276\n",
      "Epoch 90/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22747.0341 - mean_absolute_error: 129.0278 - val_loss: 15856.6637 - val_mean_absolute_error: 110.3191\n",
      "Epoch 91/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 22491.5919 - mean_absolute_error: 127.4233 - val_loss: 16017.7481 - val_mean_absolute_error: 112.5143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22574.1164 - mean_absolute_error: 129.7047 - val_loss: 16367.2105 - val_mean_absolute_error: 115.3236\n",
      "Epoch 93/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22652.0807 - mean_absolute_error: 131.6195 - val_loss: 16318.0324 - val_mean_absolute_error: 115.0015\n",
      "Epoch 94/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 23180.1236 - mean_absolute_error: 129.5049 - val_loss: 15831.2598 - val_mean_absolute_error: 109.3134\n",
      "Epoch 95/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22522.5416 - mean_absolute_error: 128.2661 - val_loss: 16362.1314 - val_mean_absolute_error: 115.2911\n",
      "Epoch 96/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22784.4535 - mean_absolute_error: 132.2548 - val_loss: 16300.9894 - val_mean_absolute_error: 114.8861\n",
      "Epoch 97/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22589.7885 - mean_absolute_error: 130.4895 - val_loss: 16086.4490 - val_mean_absolute_error: 113.1983\n",
      "Epoch 98/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22530.8220 - mean_absolute_error: 127.6670 - val_loss: 15872.5531 - val_mean_absolute_error: 110.6430\n",
      "Epoch 99/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22542.8332 - mean_absolute_error: 128.8941 - val_loss: 16203.6898 - val_mean_absolute_error: 114.1827\n",
      "Epoch 100/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22621.8186 - mean_absolute_error: 131.1840 - val_loss: 16426.8109 - val_mean_absolute_error: 115.6949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2025ba1c710>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mutls.plot_model(X_train, X_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second model, category model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_category = mutls.get_y_category(y_actual=Y, min_edge=200, bin_width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_counts = mutls.get_class_count(Y_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 18, 1.0: 23, 2.0: 40, 3.0: 44, 4.0: 14, 5.0: 7, 6.0: 8, 7.0: 4, 8.0: 6, 9.0: 3, 10.0: 12, 11.0: 10, 12.0: 7, 13.0: 4, 14.0: 7, 15.0: 10, 16.0: 5, 17.0: 10, 18.0: 6, 19.0: 6, 20.0: 6, 21.0: 3, 22.0: 4, 23.0: 2, 24.0: 2, 25.0: 2, 28.0: 1, 29.0: 2, 30.0: 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(cls_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 137)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cat = mutls.combine_columns((X_fp, Y_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled=mutls.subsampling(d_cat,-1,15,cls_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[224, 255, 255, ..., 0, 0, 3.0],\n",
       "       [224, 255, 255, ..., 0, 0, 3.0],\n",
       "       [224, 255, 255, ..., 0, 0, 1.0],\n",
       "       ...,\n",
       "       [224, 255, 255, ..., 0, 0, 10.0],\n",
       "       [224, 255, 255, ..., 0, 0, 10.0],\n",
       "       [224, 255, 255, ..., 0, 0, 29.0]], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 137)\n",
      "(20, 137)\n",
      "(177, 31)\n",
      "(20, 31)\n"
     ]
    }
   ],
   "source": [
    "X, y = subsampled[:,0:-1], subsampled[:,-1]\n",
    "y_onehot = mutls.onehot_encode_y(y=y, num_class=31)\n",
    "X_train, X_test, y_train, y_test = utils.splitData(X, y_onehot, ratio=0.10)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd fingerprint model RNN LSTM with category Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 137, 224)          202496    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 137, 224)          0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 384)               935424    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 31)                11935     \n",
      "=================================================================\n",
      "Total params: 1,149,855\n",
      "Trainable params: 1,149,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "rnn1_size = 224\n",
    "rnn2_size = 384\n",
    "dropout_rate = 0.2\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "num_classes = 31\n",
    "optimizer = 'adam' #use adam optimizer\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(LSTM(rnn1_size, return_sequences=True, input_shape=(137,1))) #137\n",
    "model_1.add(Dropout(0.3))\n",
    "model_1.add(LSTM(rnn2_size))\n",
    "model_1.add(Dropout(0.3))\n",
    "model_1.add(Dense(num_classes, activation='softmax'))\n",
    "model_1.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 3.3985 - acc: 0.0678 - val_loss: 3.6953 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 9s 50ms/step - loss: 3.2996 - acc: 0.0734 - val_loss: 3.3716 - val_acc: 0.0500\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 3.2748 - acc: 0.0508 - val_loss: 3.4042 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 12s 68ms/step - loss: 3.1691 - acc: 0.0734 - val_loss: 4.6653 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 12s 69ms/step - loss: 3.3672 - acc: 0.0791 - val_loss: 3.3349 - val_acc: 0.1000\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 15s 82ms/step - loss: 3.2352 - acc: 0.0678 - val_loss: 3.3266 - val_acc: 0.1000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 3.2201 - acc: 0.0565 - val_loss: 3.4638 - val_acc: 0.1000\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 13s 71ms/step - loss: 3.2109 - acc: 0.0847 - val_loss: 3.3898 - val_acc: 0.1000\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 13s 71ms/step - loss: 3.1986 - acc: 0.0621 - val_loss: 3.4146 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 12s 66ms/step - loss: 3.1638 - acc: 0.0847 - val_loss: 3.7467 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 3.2032 - acc: 0.0678 - val_loss: 3.3875 - val_acc: 0.1000\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 3.1792 - acc: 0.0847 - val_loss: 3.4021 - val_acc: 0.1000\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 3.1466 - acc: 0.1243 - val_loss: 3.4317 - val_acc: 0.0500\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 3.0705 - acc: 0.1073 - val_loss: 3.6064 - val_acc: 0.0500\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 3.0194 - acc: 0.0678 - val_loss: 3.4039 - val_acc: 0.0500\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.9406 - acc: 0.0904 - val_loss: 3.5234 - val_acc: 0.1000\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 2.8985 - acc: 0.1469 - val_loss: 3.4969 - val_acc: 0.0500\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 12s 67ms/step - loss: 2.9275 - acc: 0.1299 - val_loss: 3.4806 - val_acc: 0.1000\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 12s 69ms/step - loss: 2.9294 - acc: 0.0791 - val_loss: 3.4804 - val_acc: 0.2000\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.8752 - acc: 0.1186 - val_loss: 3.5255 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.8305 - acc: 0.1582 - val_loss: 3.4755 - val_acc: 0.1500\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 12s 69ms/step - loss: 2.7667 - acc: 0.1751 - val_loss: 3.4992 - val_acc: 0.2000\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 2.7802 - acc: 0.1469 - val_loss: 3.5063 - val_acc: 0.1500\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.7005 - acc: 0.1695 - val_loss: 3.7068 - val_acc: 0.1500\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.7456 - acc: 0.1751 - val_loss: 3.6184 - val_acc: 0.1500\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.7616 - acc: 0.1638 - val_loss: 3.6612 - val_acc: 0.0500\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 2.7978 - acc: 0.1412 - val_loss: 3.5955 - val_acc: 0.1500\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.8461 - acc: 0.1525 - val_loss: 3.5989 - val_acc: 0.0500\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 2.7578 - acc: 0.1469 - val_loss: 3.6461 - val_acc: 0.1000\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.7787 - acc: 0.1299 - val_loss: 3.5149 - val_acc: 0.2000\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.7550 - acc: 0.1356 - val_loss: 3.5698 - val_acc: 0.1000\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.6970 - acc: 0.1412 - val_loss: 3.5850 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 2.7276 - acc: 0.1186 - val_loss: 3.5839 - val_acc: 0.0500\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 2.7437 - acc: 0.1356 - val_loss: 3.5949 - val_acc: 0.2500\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 2.7205 - acc: 0.1695 - val_loss: 3.5807 - val_acc: 0.1000\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 2.6691 - acc: 0.1582 - val_loss: 3.5369 - val_acc: 0.2000\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 2.6565 - acc: 0.1469 - val_loss: 3.5420 - val_acc: 0.2000\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 12s 66ms/step - loss: 2.6440 - acc: 0.1638 - val_loss: 3.6795 - val_acc: 0.0500\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.7067 - acc: 0.1469 - val_loss: 3.6249 - val_acc: 0.1500\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 2.7064 - acc: 0.1299 - val_loss: 3.5745 - val_acc: 0.1500\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.6196 - acc: 0.1921 - val_loss: 3.5861 - val_acc: 0.1500\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 2.6049 - acc: 0.1751 - val_loss: 3.6438 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 12s 66ms/step - loss: 2.6131 - acc: 0.1356 - val_loss: 3.6417 - val_acc: 0.0500\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 2.8211 - acc: 0.1130 - val_loss: 3.7999 - val_acc: 0.1000\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 12s 69ms/step - loss: 2.6572 - acc: 0.1469 - val_loss: 3.6039 - val_acc: 0.1500\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 13s 75ms/step - loss: 2.7083 - acc: 0.1412 - val_loss: 3.5312 - val_acc: 0.2500\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 12s 68ms/step - loss: 2.6793 - acc: 0.1073 - val_loss: 3.7189 - val_acc: 0.1500\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 2.7385 - acc: 0.1412 - val_loss: 3.5040 - val_acc: 0.2000\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 2.6282 - acc: 0.1356 - val_loss: 3.5498 - val_acc: 0.2000\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.5675 - acc: 0.1469 - val_loss: 3.6616 - val_acc: 0.1500\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 2.6349 - acc: 0.1525 - val_loss: 3.6236 - val_acc: 0.1000\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.6063 - acc: 0.1469 - val_loss: 3.7137 - val_acc: 0.0500\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.5476 - acc: 0.1864 - val_loss: 3.6518 - val_acc: 0.1500\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.6106 - acc: 0.1638 - val_loss: 3.6930 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 12s 66ms/step - loss: 2.5985 - acc: 0.1525 - val_loss: 3.6892 - val_acc: 0.1000\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.6031 - acc: 0.1751 - val_loss: 3.6841 - val_acc: 0.1500\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 10s 59ms/step - loss: 2.5801 - acc: 0.1525 - val_loss: 3.7005 - val_acc: 0.1000\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 10s 59ms/step - loss: 2.7461 - acc: 0.1186 - val_loss: 3.6442 - val_acc: 0.1000\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 10s 58ms/step - loss: 2.6544 - acc: 0.1186 - val_loss: 3.6123 - val_acc: 0.1500\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 12s 66ms/step - loss: 2.5983 - acc: 0.1977 - val_loss: 3.5441 - val_acc: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "177/177 [==============================] - 12s 66ms/step - loss: 2.5051 - acc: 0.2034 - val_loss: 3.5730 - val_acc: 0.1000\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 12s 67ms/step - loss: 2.5998 - acc: 0.2373 - val_loss: 3.6315 - val_acc: 0.1000\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.5427 - acc: 0.1695 - val_loss: 3.6185 - val_acc: 0.1500\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.5352 - acc: 0.1582 - val_loss: 3.6107 - val_acc: 0.2000\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 2.4657 - acc: 0.1864 - val_loss: 3.5976 - val_acc: 0.1500\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 2.4651 - acc: 0.1638 - val_loss: 3.5977 - val_acc: 0.2000\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 12s 67ms/step - loss: 2.5105 - acc: 0.1695 - val_loss: 3.5965 - val_acc: 0.1500\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 2.4341 - acc: 0.1977 - val_loss: 3.6459 - val_acc: 0.0500\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 2.4553 - acc: 0.1864 - val_loss: 3.7262 - val_acc: 0.0500\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 12s 67ms/step - loss: 2.4579 - acc: 0.1582 - val_loss: 3.8664 - val_acc: 0.1000\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 2.5390 - acc: 0.1638 - val_loss: 3.7871 - val_acc: 0.1000\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 2.5018 - acc: 0.1356 - val_loss: 3.6898 - val_acc: 0.1000\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 12s 67ms/step - loss: 2.4744 - acc: 0.1525 - val_loss: 3.7143 - val_acc: 0.1500\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 2.3932 - acc: 0.1864 - val_loss: 3.6346 - val_acc: 0.2000\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 2.4638 - acc: 0.1695 - val_loss: 3.6485 - val_acc: 0.1500\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 12s 69ms/step - loss: 2.4336 - acc: 0.1808 - val_loss: 3.6928 - val_acc: 0.1500\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 13s 75ms/step - loss: 2.4448 - acc: 0.2090 - val_loss: 3.7322 - val_acc: 0.1500\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 2.4268 - acc: 0.1921 - val_loss: 3.7344 - val_acc: 0.1000\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 2.4499 - acc: 0.2147 - val_loss: 3.7256 - val_acc: 0.1500\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.3871 - acc: 0.1864 - val_loss: 3.7222 - val_acc: 0.1500\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 2.3454 - acc: 0.1921 - val_loss: 3.7732 - val_acc: 0.1000\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 12s 68ms/step - loss: 2.3465 - acc: 0.2203 - val_loss: 3.7002 - val_acc: 0.1000\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 13s 72ms/step - loss: 2.3384 - acc: 0.2090 - val_loss: 3.7391 - val_acc: 0.0500\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 11s 59ms/step - loss: 2.4351 - acc: 0.1638 - val_loss: 3.7237 - val_acc: 0.1500\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 2.3774 - acc: 0.1808 - val_loss: 3.7188 - val_acc: 0.1500\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.3359 - acc: 0.1977 - val_loss: 3.7876 - val_acc: 0.0500\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 12s 69ms/step - loss: 2.5527 - acc: 0.1751 - val_loss: 3.7112 - val_acc: 0.1500\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.3866 - acc: 0.2090 - val_loss: 3.6898 - val_acc: 0.1500\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.3640 - acc: 0.1864 - val_loss: 3.9738 - val_acc: 0.0500\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 2.6634 - acc: 0.1412 - val_loss: 3.7412 - val_acc: 0.0500\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 11s 64ms/step - loss: 2.4210 - acc: 0.1808 - val_loss: 3.7492 - val_acc: 0.1000\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.3384 - acc: 0.1977 - val_loss: 3.6732 - val_acc: 0.1500\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.3124 - acc: 0.2203 - val_loss: 3.8573 - val_acc: 0.0500\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 12s 66ms/step - loss: 2.6349 - acc: 0.1751 - val_loss: 3.9335 - val_acc: 0.1000\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 13s 73ms/step - loss: 2.5497 - acc: 0.1582 - val_loss: 3.8995 - val_acc: 0.1000\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 12s 68ms/step - loss: 2.5191 - acc: 0.1638 - val_loss: 3.7096 - val_acc: 0.0500\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 2.5919 - acc: 0.1412 - val_loss: 4.0951 - val_acc: 0.0500\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 2.4813 - acc: 0.1695 - val_loss: 3.6723 - val_acc: 0.0500\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 2.3991 - acc: 0.2147 - val_loss: 3.8151 - val_acc: 0.0500\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 2.3719 - acc: 0.2034 - val_loss: 3.7137 - val_acc: 0.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae6a9278d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "\n",
    "model_1.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training acc 0.25, testing accuracy 0.05 (max 0.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_speedcom",
   "language": "python",
   "name": "test_speedcom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
