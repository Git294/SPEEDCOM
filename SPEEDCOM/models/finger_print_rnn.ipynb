{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yang\\.conda\\envs\\test_speedcom\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataUtils import DataUtils as utils\n",
    "from model_utils import ModelUtils as mutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, Conv1D, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('temp_cfprint.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>name_smiles</th>\n",
       "      <th>Wavelength</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Quantum Yield</th>\n",
       "      <th>cfp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Benzene</td>\n",
       "      <td>C1=CC=CC=C1</td>\n",
       "      <td>254.75</td>\n",
       "      <td>210</td>\n",
       "      <td>0.053</td>\n",
       "      <td>[224, 255, 255, 255, 0, 8, 0, 0, 3, 0, 0, 0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Toluene</td>\n",
       "      <td>CC1=CC=CC=C1</td>\n",
       "      <td>261.75</td>\n",
       "      <td>2860</td>\n",
       "      <td>0.170</td>\n",
       "      <td>[224, 255, 255, 255, 0, 8, 0, 0, 11, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>o-Xylene</td>\n",
       "      <td>CC1=CC=CC=C1C</td>\n",
       "      <td>263.00</td>\n",
       "      <td>254</td>\n",
       "      <td>0.170</td>\n",
       "      <td>[224, 255, 255, 255, 0, 8, 0, 0, 10, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>m-Xylene</td>\n",
       "      <td>CC1=CC(=CC=C1)C</td>\n",
       "      <td>265.00</td>\n",
       "      <td>284</td>\n",
       "      <td>0.130</td>\n",
       "      <td>[224, 255, 255, 255, 0, 8, 0, 0, 12, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>p-Xylene</td>\n",
       "      <td>CC1=CC=C(C=C1)C</td>\n",
       "      <td>275.00</td>\n",
       "      <td>770</td>\n",
       "      <td>0.220</td>\n",
       "      <td>[224, 255, 255, 255, 0, 8, 0, 0, 8, 0, 0, 0, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #      Name      name_smiles  Wavelength  Epsilon  Quantum Yield  \\\n",
       "0  1   Benzene      C1=CC=CC=C1      254.75      210          0.053   \n",
       "1  2   Toluene     CC1=CC=CC=C1      261.75     2860          0.170   \n",
       "2  3  o-Xylene    CC1=CC=CC=C1C      263.00      254          0.170   \n",
       "3  4  m-Xylene  CC1=CC(=CC=C1)C      265.00      284          0.130   \n",
       "4  5  p-Xylene  CC1=CC=C(C=C1)C      275.00      770          0.220   \n",
       "\n",
       "                                                 cfp  \n",
       "0  [224, 255, 255, 255, 0, 8, 0, 0, 3, 0, 0, 0, 2...  \n",
       "1  [224, 255, 255, 255, 0, 8, 0, 0, 11, 0, 0, 0, ...  \n",
       "2  [224, 255, 255, 255, 0, 8, 0, 0, 10, 0, 0, 0, ...  \n",
       "3  [224, 255, 255, 255, 0, 8, 0, 0, 12, 0, 0, 0, ...  \n",
       "4  [224, 255, 255, 255, 0, 8, 0, 0, 8, 0, 0, 0, 1...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fingerprint column shape is (267, 137)\n"
     ]
    }
   ],
   "source": [
    "X_fp=utils.finger_print_clean(df=df,colname_string_array='cfp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 137)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.values[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model original Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cat = mutls.combine_columns((X_fp, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = d_cat[:,0:-1], d_cat[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([254.75, 261.75, 263.0, 265.0, 275.0, 265.0, 278.0, 271.0, 271.0,\n",
       "       270.75, 220.0, 222.0, 242.0, 227.0, 241.0, 288.0, 251.0, 279.0,\n",
       "       265.0, 228.0, 258.0, 248.0, 236.0, 274.0, 277.0, 227.0, 222.0,\n",
       "       218.0, 310.25, 291.0, 240.0, 251.0, 263.0, 245.0, 302.0, 252.0,\n",
       "       283.0, 225.0, 316.0, 230.0, 442.0, 247.5, 276.25, 294.75, 312.0,\n",
       "       251.0, 206.0, 209.0, 212.0, 245.0, 223.0, 278.0, 275.0, 356.25,\n",
       "       475.0, 578.0, 252.0, 241.0, 258.0, 372.5, 270.25, 303.0, 228.0,\n",
       "       239.0, 245.0, 218.0, 227.0, 235.0, 278.75, 276.0, 293.75, 326.0,\n",
       "       330.0, 353.25, 432.25, 425.0, 372.0, 451.0, 251.0, 276.0, 227.0,\n",
       "       257.0, 265.0, 270.0, 215.0, 281.0, 238.0, 204.0, 219.0, 245.0,\n",
       "       217.0, 253.0, 231.75, 206.0, 278.0, 502.0, 413.0, 286.0, 336.0,\n",
       "       460.5, 219.0, 413.0, 247.0, 349.0, 262.0, 257.5, 274.25, 211.0,\n",
       "       278.0, 261.0, 243.0, 266.75, 263.75, 258.25, 228.0, 259.0, 212.0,\n",
       "       263.0, 265.0, 206.0, 248.0, 281.0, 239.75, 225.0, 288.0, 211.0,\n",
       "       270.0, 287.0, 458.0, 243.0, 258.0, 267.0, 401.0, 246.0, 280.0,\n",
       "       251.0, 268.0, 249.0, 251.25, 248.0, 250.0, 233.0, 296.0, 303.0,\n",
       "       275.0, 280.0, 326.0, 338.0, 323.75, 373.25, 459.25, 436.0, 407.5,\n",
       "       384.0, 436.0, 444.75, 361.0, 278.0, 247.0, 261.0, 270.5, 264.0,\n",
       "       249.0, 248.0, 533.0, 278.0, 587.0, 253.0, 605.0, 656.0, 654.0,\n",
       "       628.0, 237.0, 239.0, 642.5, 603.0, 519.4, 627.5, 319.0, 430.0,\n",
       "       466.0, 478.0, 486.0, 503.0, 481.0, 498.0, 555.0, 530.0, 512.0,\n",
       "       563.0, 504.0, 518.0, 619.0, 513.0, 483.0, 497.0, 606.0, 524.25,\n",
       "       603.5, 711.0, 592.0, 709.5, 818.0, 485.0, 582.0, 687.5, 544.25,\n",
       "       789.0, 559.25, 655.75, 763.25, 559.5, 431.25, 616.5, 590.5, 543.0,\n",
       "       590.0, 554.0, 558.0, 573.0, 597.0, 435.75, 500.25, 502.0, 535.0,\n",
       "       559.0, 261.0, 511.75, 542.75, 553.0, 529.75, 565.0, 576.0, 338.5,\n",
       "       279.75, 325.0, 249.0, 285.0, 345.5, 627.25, 276.0, 424.0, 205.0,\n",
       "       203.0, 208.0, 396.25, 402.0, 409.75, 408.0, 385.9, 429.0, 491.0,\n",
       "       450.75, 377.0, 361.0, 698.5, 674.0, 674.0, 569.0, 429.0, 453.0,\n",
       "       410.0, 413.0, 414.0, 401.0, 413.0, 780.2], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213, 137)\n",
      "(54, 137)\n",
      "(213, 1)\n",
      "(54, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = utils.splitData(X, y, ratio=0.20)\n",
    "y_train = np.reshape(y_train, (-1, 1))\n",
    "y_test = np.reshape(y_test, (-1, 1))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_int_counts = len(np.unique(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
       "       53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
       "       70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 88, 89, 90,\n",
       "       92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 106, 108, 109,\n",
       "       110, 112, 113, 114, 116, 117, 118, 120, 121, 122, 124, 125, 126,\n",
       "       128, 129, 130, 132, 133, 134, 136, 137, 138, 140, 141, 142, 144,\n",
       "       145, 146, 148, 149, 150, 152, 153, 154, 156, 157, 158, 160, 161,\n",
       "       162, 164, 165, 166, 168, 169, 170, 172, 173, 174, 176, 177, 178,\n",
       "       180, 181, 182, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196,\n",
       "       197, 198, 200, 201, 202, 204, 205, 206, 208, 209, 210, 212, 213,\n",
       "       214, 216, 217, 218, 220, 221, 222, 224, 225, 226, 228, 229, 230,\n",
       "       232, 233, 234, 236, 237, 238, 240, 241, 242, 244, 245, 246, 248,\n",
       "       249, 250, 252, 253, 254, 255], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_int_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 137)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yang\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Yang\\.conda\\envs\\test_speedcom\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 137, 50)           12800     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 137, 50)           20200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 137, 50)           20200     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 137, 50)           20200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 137, 50)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 137, 50)           2550      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6850)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6851      \n",
      "=================================================================\n",
      "Total params: 82,801\n",
      "Trainable params: 82,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(256, hidden_size, input_length= X.shape[1]))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(hidden_size, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mean_absolute_error'])\n",
    "model.summary() ##use mean_squared_error loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yang\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 213 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "213/213 [==============================] - 6s 29ms/step - loss: 160379.1317 - mean_absolute_error: 371.3096 - val_loss: 134951.5286 - val_mean_absolute_error: 345.1137\n",
      "Epoch 2/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 152943.6567 - mean_absolute_error: 360.9150 - val_loss: 113847.8487 - val_mean_absolute_error: 312.9310\n",
      "Epoch 3/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 115158.2079 - mean_absolute_error: 304.2075 - val_loss: 69818.1665 - val_mean_absolute_error: 232.3322\n",
      "Epoch 4/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 63348.9899 - mean_absolute_error: 198.0327 - val_loss: 23348.1945 - val_mean_absolute_error: 100.9977\n",
      "Epoch 5/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 27028.3849 - mean_absolute_error: 132.7507 - val_loss: 23013.9338 - val_mean_absolute_error: 136.4390\n",
      "Epoch 6/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 28404.5646 - mean_absolute_error: 151.4141 - val_loss: 21631.1641 - val_mean_absolute_error: 132.5751\n",
      "Epoch 7/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 24058.2143 - mean_absolute_error: 136.8281 - val_loss: 15840.1752 - val_mean_absolute_error: 109.8615\n",
      "Epoch 8/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 23433.3809 - mean_absolute_error: 125.1686 - val_loss: 16150.4565 - val_mean_absolute_error: 105.2222\n",
      "Epoch 9/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 23272.8462 - mean_absolute_error: 124.9203 - val_loss: 15875.6099 - val_mean_absolute_error: 110.7014\n",
      "Epoch 10/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22329.4266 - mean_absolute_error: 128.9524 - val_loss: 16633.0392 - val_mean_absolute_error: 116.8534\n",
      "Epoch 11/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22878.4897 - mean_absolute_error: 132.8699 - val_loss: 17042.0857 - val_mean_absolute_error: 118.7737\n",
      "Epoch 12/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22793.7538 - mean_absolute_error: 131.4398 - val_loss: 16086.4680 - val_mean_absolute_error: 113.1976\n",
      "Epoch 13/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22661.6414 - mean_absolute_error: 128.5038 - val_loss: 15939.1002 - val_mean_absolute_error: 111.6661\n",
      "Epoch 14/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22451.8048 - mean_absolute_error: 128.0031 - val_loss: 16028.6921 - val_mean_absolute_error: 112.6278\n",
      "Epoch 15/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22722.4595 - mean_absolute_error: 130.2893 - val_loss: 16292.4049 - val_mean_absolute_error: 114.8267\n",
      "Epoch 16/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22552.9342 - mean_absolute_error: 130.0162 - val_loss: 16281.6869 - val_mean_absolute_error: 114.7523\n",
      "Epoch 17/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22654.5984 - mean_absolute_error: 129.8209 - val_loss: 16100.9813 - val_mean_absolute_error: 113.3305\n",
      "Epoch 18/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22565.2469 - mean_absolute_error: 129.0142 - val_loss: 16070.7580 - val_mean_absolute_error: 113.0499\n",
      "Epoch 19/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22491.3742 - mean_absolute_error: 128.8078 - val_loss: 16152.6087 - val_mean_absolute_error: 113.7757\n",
      "Epoch 20/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22528.0742 - mean_absolute_error: 129.1138 - val_loss: 16171.6927 - val_mean_absolute_error: 113.9311\n",
      "Epoch 21/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22559.2381 - mean_absolute_error: 129.7147 - val_loss: 16169.0268 - val_mean_absolute_error: 113.9097\n",
      "Epoch 22/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22668.4666 - mean_absolute_error: 130.8433 - val_loss: 16456.6995 - val_mean_absolute_error: 115.8738\n",
      "Epoch 23/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22658.4771 - mean_absolute_error: 131.2340 - val_loss: 16226.9983 - val_mean_absolute_error: 114.3585\n",
      "Epoch 24/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22851.9126 - mean_absolute_error: 128.9154 - val_loss: 15835.0624 - val_mean_absolute_error: 109.6400\n",
      "Epoch 25/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22618.4201 - mean_absolute_error: 127.7005 - val_loss: 16134.2082 - val_mean_absolute_error: 113.6217\n",
      "Epoch 26/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22404.1697 - mean_absolute_error: 129.5968 - val_loss: 16383.6222 - val_mean_absolute_error: 115.4277\n",
      "Epoch 27/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22579.7479 - mean_absolute_error: 130.8631 - val_loss: 16249.4576 - val_mean_absolute_error: 114.5235\n",
      "Epoch 28/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22531.1092 - mean_absolute_error: 129.7284 - val_loss: 16033.0007 - val_mean_absolute_error: 112.6737\n",
      "Epoch 29/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22537.5725 - mean_absolute_error: 128.2789 - val_loss: 15947.8663 - val_mean_absolute_error: 111.7741\n",
      "Epoch 30/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22606.6964 - mean_absolute_error: 128.1094 - val_loss: 16069.8557 - val_mean_absolute_error: 113.0419\n",
      "Epoch 31/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22562.3591 - mean_absolute_error: 129.5642 - val_loss: 16401.7673 - val_mean_absolute_error: 115.5413\n",
      "Epoch 32/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22552.9909 - mean_absolute_error: 130.5618 - val_loss: 16239.4995 - val_mean_absolute_error: 114.4513\n",
      "Epoch 33/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22574.8306 - mean_absolute_error: 129.8919 - val_loss: 16094.6367 - val_mean_absolute_error: 113.2741\n",
      "Epoch 34/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22687.8422 - mean_absolute_error: 128.6883 - val_loss: 15880.7236 - val_mean_absolute_error: 110.8019\n",
      "Epoch 35/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22552.3070 - mean_absolute_error: 127.7556 - val_loss: 16211.5534 - val_mean_absolute_error: 114.2435\n",
      "Epoch 36/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22516.4653 - mean_absolute_error: 130.5894 - val_loss: 16510.8634 - val_mean_absolute_error: 116.1889\n",
      "Epoch 37/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22715.6509 - mean_absolute_error: 130.6753 - val_loss: 16128.6963 - val_mean_absolute_error: 113.5781\n",
      "Epoch 38/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22803.8212 - mean_absolute_error: 129.0822 - val_loss: 16053.5297 - val_mean_absolute_error: 112.8988\n",
      "Epoch 39/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22799.3084 - mean_absolute_error: 131.2444 - val_loss: 16385.4710 - val_mean_absolute_error: 115.4391\n",
      "Epoch 40/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22999.9868 - mean_absolute_error: 129.1980 - val_loss: 15843.9512 - val_mean_absolute_error: 109.9905\n",
      "Epoch 41/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22936.5564 - mean_absolute_error: 129.3499 - val_loss: 16426.6030 - val_mean_absolute_error: 115.6933\n",
      "Epoch 42/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22881.4901 - mean_absolute_error: 130.0946 - val_loss: 15956.2270 - val_mean_absolute_error: 111.8719\n",
      "Epoch 43/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22516.7050 - mean_absolute_error: 129.3381 - val_loss: 16290.0105 - val_mean_absolute_error: 114.8101\n",
      "Epoch 44/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22599.0000 - mean_absolute_error: 129.6804 - val_loss: 16078.1437 - val_mean_absolute_error: 113.1200\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 2s 10ms/step - loss: 22515.2376 - mean_absolute_error: 129.4225 - val_loss: 16340.0175 - val_mean_absolute_error: 115.1471\n",
      "Epoch 46/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22502.7993 - mean_absolute_error: 130.4169 - val_loss: 16153.9757 - val_mean_absolute_error: 113.7870\n",
      "Epoch 47/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22580.9640 - mean_absolute_error: 129.9798 - val_loss: 16040.5360 - val_mean_absolute_error: 112.7511\n",
      "Epoch 48/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22923.9164 - mean_absolute_error: 128.6792 - val_loss: 16017.2708 - val_mean_absolute_error: 112.5095\n",
      "Epoch 49/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22583.5235 - mean_absolute_error: 130.2565 - val_loss: 16409.9561 - val_mean_absolute_error: 115.5917\n",
      "Epoch 50/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22590.3316 - mean_absolute_error: 130.1435 - val_loss: 16072.2091 - val_mean_absolute_error: 113.0643\n",
      "Epoch 51/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22661.3586 - mean_absolute_error: 127.6107 - val_loss: 15889.9965 - val_mean_absolute_error: 110.9621\n",
      "Epoch 52/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22728.2917 - mean_absolute_error: 129.8041 - val_loss: 16466.4434 - val_mean_absolute_error: 115.9314\n",
      "Epoch 53/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22601.2770 - mean_absolute_error: 130.9905 - val_loss: 16257.8316 - val_mean_absolute_error: 114.5837\n",
      "Epoch 54/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22905.8657 - mean_absolute_error: 129.3635 - val_loss: 15896.8566 - val_mean_absolute_error: 111.0748\n",
      "Epoch 55/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22493.2966 - mean_absolute_error: 128.7373 - val_loss: 16335.4619 - val_mean_absolute_error: 115.1172\n",
      "Epoch 56/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22616.0779 - mean_absolute_error: 130.9188 - val_loss: 16246.7118 - val_mean_absolute_error: 114.5035\n",
      "Epoch 57/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22697.5649 - mean_absolute_error: 130.4751 - val_loss: 16037.3756 - val_mean_absolute_error: 112.7188\n",
      "Epoch 58/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22520.1370 - mean_absolute_error: 128.4608 - val_loss: 15972.9665 - val_mean_absolute_error: 112.0602\n",
      "Epoch 59/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22725.4929 - mean_absolute_error: 130.0498 - val_loss: 16229.4142 - val_mean_absolute_error: 114.3765\n",
      "Epoch 60/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22322.2279 - mean_absolute_error: 128.6912 - val_loss: 15939.0348 - val_mean_absolute_error: 111.6659\n",
      "Epoch 61/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22663.5818 - mean_absolute_error: 127.8321 - val_loss: 16071.2215 - val_mean_absolute_error: 113.0547\n",
      "Epoch 62/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22519.9952 - mean_absolute_error: 130.1644 - val_loss: 16350.7996 - val_mean_absolute_error: 115.2177\n",
      "Epoch 63/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22820.3457 - mean_absolute_error: 129.8151 - val_loss: 15973.1839 - val_mean_absolute_error: 112.0627\n",
      "Epoch 64/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22604.4427 - mean_absolute_error: 129.9263 - val_loss: 16540.8115 - val_mean_absolute_error: 116.3565\n",
      "Epoch 65/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22595.3280 - mean_absolute_error: 130.0652 - val_loss: 16072.5447 - val_mean_absolute_error: 113.0675\n",
      "Epoch 66/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22639.4034 - mean_absolute_error: 128.8632 - val_loss: 16045.8078 - val_mean_absolute_error: 112.8052\n",
      "Epoch 67/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22617.5004 - mean_absolute_error: 128.8262 - val_loss: 16090.8379 - val_mean_absolute_error: 113.2388\n",
      "Epoch 68/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22727.7506 - mean_absolute_error: 131.0380 - val_loss: 16405.9878 - val_mean_absolute_error: 115.5674\n",
      "Epoch 69/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22961.5324 - mean_absolute_error: 129.3938 - val_loss: 15902.6668 - val_mean_absolute_error: 111.1665\n",
      "Epoch 70/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22733.6400 - mean_absolute_error: 130.1947 - val_loss: 16388.9317 - val_mean_absolute_error: 115.4613\n",
      "Epoch 71/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22721.5148 - mean_absolute_error: 131.8173 - val_loss: 16333.8206 - val_mean_absolute_error: 115.1067\n",
      "Epoch 72/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22775.4120 - mean_absolute_error: 129.1183 - val_loss: 15833.5947 - val_mean_absolute_error: 109.5555\n",
      "Epoch 73/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22759.7770 - mean_absolute_error: 128.8653 - val_loss: 16335.6904 - val_mean_absolute_error: 115.1191\n",
      "Epoch 74/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22834.1670 - mean_absolute_error: 131.8043 - val_loss: 16117.6468 - val_mean_absolute_error: 113.4794\n",
      "Epoch 75/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22612.3377 - mean_absolute_error: 128.0696 - val_loss: 15901.6672 - val_mean_absolute_error: 111.1517\n",
      "Epoch 76/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22625.2733 - mean_absolute_error: 128.2713 - val_loss: 16136.6214 - val_mean_absolute_error: 113.6428\n",
      "Epoch 77/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22772.4065 - mean_absolute_error: 131.8766 - val_loss: 16866.1238 - val_mean_absolute_error: 117.9954\n",
      "Epoch 78/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22662.7851 - mean_absolute_error: 130.5274 - val_loss: 15950.1319 - val_mean_absolute_error: 111.8018\n",
      "Epoch 79/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22574.5840 - mean_absolute_error: 129.0379 - val_loss: 16120.2869 - val_mean_absolute_error: 113.5027\n",
      "Epoch 80/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22500.8540 - mean_absolute_error: 128.4868 - val_loss: 15961.1892 - val_mean_absolute_error: 111.9303\n",
      "Epoch 81/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22671.3214 - mean_absolute_error: 129.4215 - val_loss: 16159.8681 - val_mean_absolute_error: 113.8365\n",
      "Epoch 82/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22792.7917 - mean_absolute_error: 129.1698 - val_loss: 15953.8995 - val_mean_absolute_error: 111.8466\n",
      "Epoch 83/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22516.8510 - mean_absolute_error: 128.8126 - val_loss: 16384.4907 - val_mean_absolute_error: 115.4338\n",
      "Epoch 84/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22645.5261 - mean_absolute_error: 131.1570 - val_loss: 16389.5740 - val_mean_absolute_error: 115.4657\n",
      "Epoch 85/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22764.2056 - mean_absolute_error: 129.8549 - val_loss: 15989.2227 - val_mean_absolute_error: 112.2336\n",
      "Epoch 86/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22562.9775 - mean_absolute_error: 129.6776 - val_loss: 16186.7788 - val_mean_absolute_error: 114.0523\n",
      "Epoch 87/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 23296.4310 - mean_absolute_error: 129.3861 - val_loss: 15876.2201 - val_mean_absolute_error: 110.7184\n",
      "Epoch 88/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 23019.1410 - mean_absolute_error: 131.4705 - val_loss: 17083.3877 - val_mean_absolute_error: 118.9483\n",
      "Epoch 89/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22686.5787 - mean_absolute_error: 131.5068 - val_loss: 16067.4076 - val_mean_absolute_error: 113.0201\n",
      "Epoch 90/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22659.6741 - mean_absolute_error: 128.4228 - val_loss: 15871.5994 - val_mean_absolute_error: 110.6283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22660.0361 - mean_absolute_error: 129.4809 - val_loss: 16407.8465 - val_mean_absolute_error: 115.5797\n",
      "Epoch 92/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22878.2242 - mean_absolute_error: 131.8275 - val_loss: 16200.1528 - val_mean_absolute_error: 114.1569\n",
      "Epoch 93/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22554.7737 - mean_absolute_error: 128.8141 - val_loss: 15847.5324 - val_mean_absolute_error: 110.1059\n",
      "Epoch 94/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22663.6154 - mean_absolute_error: 128.5580 - val_loss: 16190.2944 - val_mean_absolute_error: 114.0807\n",
      "Epoch 95/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22755.8214 - mean_absolute_error: 131.5070 - val_loss: 16172.7291 - val_mean_absolute_error: 113.9420\n",
      "Epoch 96/100\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 22629.8180 - mean_absolute_error: 128.2414 - val_loss: 15897.5186 - val_mean_absolute_error: 111.0914\n",
      "Epoch 97/100\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 22625.6819 - mean_absolute_error: 128.2744 - val_loss: 16093.5580 - val_mean_absolute_error: 113.2667\n",
      "Epoch 98/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22457.6419 - mean_absolute_error: 129.2827 - val_loss: 16082.3772 - val_mean_absolute_error: 113.1637\n",
      "Epoch 99/100\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 22547.6754 - mean_absolute_error: 129.3683 - val_loss: 16171.3471 - val_mean_absolute_error: 113.9316\n",
      "Epoch 100/100\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 22944.2072 - mean_absolute_error: 129.8188 - val_loss: 15960.4932 - val_mean_absolute_error: 111.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19e144547f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second model, category model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_category = mutls.get_y_category(y_actual=Y, min_edge=200, bin_width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_counts = mutls.get_class_count(Y_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 18, 1.0: 23, 2.0: 40, 3.0: 44, 4.0: 14, 5.0: 7, 6.0: 8, 7.0: 4, 8.0: 6, 9.0: 3, 10.0: 12, 11.0: 10, 12.0: 7, 13.0: 4, 14.0: 7, 15.0: 10, 16.0: 5, 17.0: 10, 18.0: 6, 19.0: 6, 20.0: 6, 21.0: 3, 22.0: 4, 23.0: 2, 24.0: 2, 25.0: 2, 28.0: 1, 29.0: 2, 30.0: 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(cls_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 137)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cat = mutls.combine_columns((X_fp, Y_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subsampled=mutls.subsampling(d_cat,-1,15,cls_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[224, 255, 255, ..., 0, 0, 2.0],\n",
       "       [224, 255, 255, ..., 0, 0, 3.0],\n",
       "       [224, 255, 255, ..., 0, 0, 1.0],\n",
       "       ...,\n",
       "       [224, 255, 255, ..., 0, 0, 10.0],\n",
       "       [224, 255, 255, ..., 0, 0, 10.0],\n",
       "       [224, 255, 255, ..., 0, 0, 29.0]], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 137)\n",
      "(21, 137)\n",
      "(181, 31)\n",
      "(21, 31)\n"
     ]
    }
   ],
   "source": [
    "X, y = subsampled[:,0:-1], subsampled[:,-1]\n",
    "y_onehot = mutls.onehot_encode_y(y=y, num_class=31)\n",
    "X_train, X_test, y_train, y_test = utils.splitData(X, y_onehot, ratio=0.10)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd fingerprint model RNN LSTM with category Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 137, 224)          202496    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 384)               935424    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 31)                11935     \n",
      "=================================================================\n",
      "Total params: 1,149,855\n",
      "Trainable params: 1,149,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "rnn1_size = 224\n",
    "rnn2_size = 384\n",
    "dropout_rate = 0.2\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "num_classes = 31\n",
    "optimizer = 'adam' #use adam optimizer\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(LSTM(rnn1_size, return_sequences=True, input_shape=(137,1))) #137\n",
    "model_1.add(LSTM(rnn2_size))\n",
    "model_1.add(Dense(num_classes, activation='softmax'))\n",
    "model_1.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 181 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "181/181 [==============================] - 13s 70ms/step - loss: 3.4299 - acc: 0.0552 - val_loss: 3.3206 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 3.2880 - acc: 0.0884 - val_loss: 3.2661 - val_acc: 0.0476\n",
      "Epoch 3/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 3.2250 - acc: 0.0829 - val_loss: 3.2303 - val_acc: 0.0952\n",
      "Epoch 4/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 3.1973 - acc: 0.1050 - val_loss: 3.1175 - val_acc: 0.0952\n",
      "Epoch 5/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 3.1884 - acc: 0.0608 - val_loss: 3.1575 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 3.1696 - acc: 0.0718 - val_loss: 3.1519 - val_acc: 0.0952\n",
      "Epoch 7/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 3.2686 - acc: 0.0994 - val_loss: 3.0736 - val_acc: 0.0952\n",
      "Epoch 8/100\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 3.1907 - acc: 0.0497 - val_loss: 3.1151 - val_acc: 0.0952\n",
      "Epoch 9/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 3.1742 - acc: 0.0829 - val_loss: 3.1788 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 3.1787 - acc: 0.0939 - val_loss: 3.1591 - val_acc: 0.0952\n",
      "Epoch 11/100\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 3.1562 - acc: 0.1050 - val_loss: 3.1322 - val_acc: 0.0952\n",
      "Epoch 12/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 3.1635 - acc: 0.0718 - val_loss: 3.1652 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 3.1585 - acc: 0.0939 - val_loss: 3.1500 - val_acc: 0.0952\n",
      "Epoch 14/100\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 3.1374 - acc: 0.1160 - val_loss: 3.1240 - val_acc: 0.0952\n",
      "Epoch 15/100\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 3.1229 - acc: 0.1271 - val_loss: 3.2193 - val_acc: 0.1429\n",
      "Epoch 16/100\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 3.0939 - acc: 0.0884 - val_loss: 3.1029 - val_acc: 0.0476\n",
      "Epoch 17/100\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 3.0510 - acc: 0.0939 - val_loss: 3.1982 - val_acc: 0.0952\n",
      "Epoch 18/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 3.0056 - acc: 0.1215 - val_loss: 3.1984 - val_acc: 0.0476\n",
      "Epoch 19/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.9008 - acc: 0.1215 - val_loss: 3.3347 - val_acc: 0.1429\n",
      "Epoch 20/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.8757 - acc: 0.1381 - val_loss: 3.1780 - val_acc: 0.0952\n",
      "Epoch 21/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.8649 - acc: 0.1271 - val_loss: 3.2615 - val_acc: 0.1905\n",
      "Epoch 22/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.8108 - acc: 0.1381 - val_loss: 3.5614 - val_acc: 0.1429\n",
      "Epoch 23/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.7668 - acc: 0.1657 - val_loss: 3.5650 - val_acc: 0.1429\n",
      "Epoch 24/100\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 2.7889 - acc: 0.1713 - val_loss: 3.5180 - val_acc: 0.1429\n",
      "Epoch 25/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.8303 - acc: 0.1381 - val_loss: 3.5009 - val_acc: 0.1429\n",
      "Epoch 26/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.7291 - acc: 0.1492 - val_loss: 3.4968 - val_acc: 0.1429\n",
      "Epoch 27/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.6574 - acc: 0.1768 - val_loss: 3.6394 - val_acc: 0.0476\n",
      "Epoch 28/100\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 2.6652 - acc: 0.1713 - val_loss: 3.7230 - val_acc: 0.0952\n",
      "Epoch 29/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.6077 - acc: 0.2044 - val_loss: 3.6666 - val_acc: 0.1429\n",
      "Epoch 30/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5815 - acc: 0.1713 - val_loss: 3.7453 - val_acc: 0.1429\n",
      "Epoch 31/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5968 - acc: 0.1657 - val_loss: 3.7154 - val_acc: 0.0476\n",
      "Epoch 32/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 2.5684 - acc: 0.1713 - val_loss: 3.8059 - val_acc: 0.0952\n",
      "Epoch 33/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5949 - acc: 0.1934 - val_loss: 3.7297 - val_acc: 0.1429\n",
      "Epoch 34/100\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 2.5814 - acc: 0.1602 - val_loss: 3.7953 - val_acc: 0.1429\n",
      "Epoch 35/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 2.6037 - acc: 0.1657 - val_loss: 3.8075 - val_acc: 0.1429\n",
      "Epoch 36/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 2.5609 - acc: 0.1823 - val_loss: 3.7926 - val_acc: 0.1429\n",
      "Epoch 37/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5258 - acc: 0.1878 - val_loss: 3.7158 - val_acc: 0.0952\n",
      "Epoch 38/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5688 - acc: 0.1878 - val_loss: 3.7739 - val_acc: 0.0476\n",
      "Epoch 39/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5637 - acc: 0.1823 - val_loss: 3.6974 - val_acc: 0.0952\n",
      "Epoch 40/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5245 - acc: 0.1547 - val_loss: 3.7760 - val_acc: 0.1429\n",
      "Epoch 41/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5511 - acc: 0.1602 - val_loss: 3.8559 - val_acc: 0.0952\n",
      "Epoch 42/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5969 - acc: 0.1657 - val_loss: 3.9907 - val_acc: 0.0952\n",
      "Epoch 43/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5228 - acc: 0.1878 - val_loss: 3.8910 - val_acc: 0.0952\n",
      "Epoch 44/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5095 - acc: 0.1934 - val_loss: 3.8689 - val_acc: 0.1429\n",
      "Epoch 45/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.4410 - acc: 0.2155 - val_loss: 3.7620 - val_acc: 0.1429\n",
      "Epoch 46/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.4195 - acc: 0.1934 - val_loss: 3.8579 - val_acc: 0.0952\n",
      "Epoch 47/100\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 2.3751 - acc: 0.2155 - val_loss: 3.8327 - val_acc: 0.0952\n",
      "Epoch 48/100\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 2.3787 - acc: 0.2210 - val_loss: 3.9726 - val_acc: 0.0952\n",
      "Epoch 49/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.4249 - acc: 0.1768 - val_loss: 4.0281 - val_acc: 0.0476\n",
      "Epoch 50/100\n",
      "181/181 [==============================] - 9s 52ms/step - loss: 2.3825 - acc: 0.2099 - val_loss: 4.0269 - val_acc: 0.0952\n",
      "Epoch 51/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 2.4302 - acc: 0.1878 - val_loss: 3.8986 - val_acc: 0.0952\n",
      "Epoch 52/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3339 - acc: 0.1878 - val_loss: 3.9934 - val_acc: 0.0952\n",
      "Epoch 53/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3046 - acc: 0.2099 - val_loss: 4.1259 - val_acc: 0.0952\n",
      "Epoch 54/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 2.3081 - acc: 0.2320 - val_loss: 4.0815 - val_acc: 0.0952\n",
      "Epoch 55/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.2798 - acc: 0.2265 - val_loss: 4.1101 - val_acc: 0.1429\n",
      "Epoch 56/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.2612 - acc: 0.2265 - val_loss: 4.1494 - val_acc: 0.1905\n",
      "Epoch 57/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3234 - acc: 0.1823 - val_loss: 4.1826 - val_acc: 0.0952\n",
      "Epoch 58/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3790 - acc: 0.1823 - val_loss: 4.4563 - val_acc: 0.0476\n",
      "Epoch 59/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.4123 - acc: 0.2155 - val_loss: 4.1432 - val_acc: 0.1429\n",
      "Epoch 60/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3022 - acc: 0.1878 - val_loss: 4.1203 - val_acc: 0.0952\n",
      "Epoch 61/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3097 - acc: 0.2099 - val_loss: 4.1649 - val_acc: 0.0952\n",
      "Epoch 62/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.2642 - acc: 0.2210 - val_loss: 4.3512 - val_acc: 0.0476\n",
      "Epoch 63/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3860 - acc: 0.2099 - val_loss: 4.0911 - val_acc: 0.1429\n",
      "Epoch 64/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.5115 - acc: 0.1657 - val_loss: 4.0112 - val_acc: 0.0476\n",
      "Epoch 65/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.4498 - acc: 0.1823 - val_loss: 4.0388 - val_acc: 0.1429\n",
      "Epoch 66/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3454 - acc: 0.2099 - val_loss: 4.0627 - val_acc: 0.0952\n",
      "Epoch 67/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3191 - acc: 0.2210 - val_loss: 4.0128 - val_acc: 0.1905\n",
      "Epoch 68/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.2909 - acc: 0.2044 - val_loss: 4.1818 - val_acc: 0.0952\n",
      "Epoch 69/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.2771 - acc: 0.2099 - val_loss: 4.2062 - val_acc: 0.0476\n",
      "Epoch 70/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.2427 - acc: 0.2265 - val_loss: 4.3633 - val_acc: 0.0952\n",
      "Epoch 71/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.2053 - acc: 0.1989 - val_loss: 4.2074 - val_acc: 0.0952\n",
      "Epoch 72/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.1640 - acc: 0.2376 - val_loss: 4.3666 - val_acc: 0.1429\n",
      "Epoch 73/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.1489 - acc: 0.2431 - val_loss: 4.6999 - val_acc: 0.1429\n",
      "Epoch 74/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.1310 - acc: 0.2265 - val_loss: 4.5294 - val_acc: 0.1429\n",
      "Epoch 75/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.1183 - acc: 0.2210 - val_loss: 4.7381 - val_acc: 0.0952\n",
      "Epoch 76/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 2.1107 - acc: 0.2541 - val_loss: 4.5954 - val_acc: 0.0952\n",
      "Epoch 77/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.1275 - acc: 0.2265 - val_loss: 4.4722 - val_acc: 0.0952\n",
      "Epoch 78/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.1516 - acc: 0.2265 - val_loss: 4.7515 - val_acc: 0.1429\n",
      "Epoch 79/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.1417 - acc: 0.2431 - val_loss: 4.4897 - val_acc: 0.1905\n",
      "Epoch 80/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.1840 - acc: 0.2431 - val_loss: 4.7584 - val_acc: 0.0952\n",
      "Epoch 81/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.1905 - acc: 0.2431 - val_loss: 4.4317 - val_acc: 0.0952\n",
      "Epoch 82/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.2984 - acc: 0.2376 - val_loss: 4.2778 - val_acc: 0.1429\n",
      "Epoch 83/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3316 - acc: 0.1989 - val_loss: 4.8080 - val_acc: 0.0952\n",
      "Epoch 84/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.3232 - acc: 0.2155 - val_loss: 4.4059 - val_acc: 0.1429\n",
      "Epoch 85/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.1590 - acc: 0.2210 - val_loss: 4.1545 - val_acc: 0.0952\n",
      "Epoch 86/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0893 - acc: 0.2541 - val_loss: 4.4430 - val_acc: 0.0952\n",
      "Epoch 87/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0978 - acc: 0.2376 - val_loss: 4.4641 - val_acc: 0.2381\n",
      "Epoch 88/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0727 - acc: 0.2431 - val_loss: 4.8445 - val_acc: 0.1905\n",
      "Epoch 89/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0328 - acc: 0.2541 - val_loss: 4.6571 - val_acc: 0.1905\n",
      "Epoch 90/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0584 - acc: 0.2210 - val_loss: 4.6703 - val_acc: 0.2857\n",
      "Epoch 91/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 1.9637 - acc: 0.2597 - val_loss: 4.7835 - val_acc: 0.1429\n",
      "Epoch 92/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 2.0077 - acc: 0.2541 - val_loss: 4.8449 - val_acc: 0.1429\n",
      "Epoch 93/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0552 - acc: 0.2431 - val_loss: 4.8974 - val_acc: 0.1429\n",
      "Epoch 94/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0226 - acc: 0.2431 - val_loss: 4.5761 - val_acc: 0.0952\n",
      "Epoch 95/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 2.0963 - acc: 0.2044 - val_loss: 4.6453 - val_acc: 0.2381\n",
      "Epoch 96/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0132 - acc: 0.2818 - val_loss: 5.2394 - val_acc: 0.1429\n",
      "Epoch 97/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0878 - acc: 0.2099 - val_loss: 4.5999 - val_acc: 0.1429\n",
      "Epoch 98/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0519 - acc: 0.2541 - val_loss: 4.9678 - val_acc: 0.0952\n",
      "Epoch 99/100\n",
      "181/181 [==============================] - 9s 51ms/step - loss: 2.0225 - acc: 0.2265 - val_loss: 5.3561 - val_acc: 0.0952\n",
      "Epoch 100/100\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 2.2176 - acc: 0.2210 - val_loss: 4.8173 - val_acc: 0.1429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a611e8d30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "\n",
    "model_1.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training acc 0.25, testing accuracy 0.05 (max 0.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_speedcom",
   "language": "python",
   "name": "test_speedcom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
