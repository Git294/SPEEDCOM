{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, Conv1D, BatchNormalization, Flatten, Dense, Dropout, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn import metrics\n",
    "\n",
    "from dataUtils import DataUtils\n",
    "from model_utils import ModelUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QY classification (binary) IMPORTANT because need to justify if emission exists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_data_emission.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, qy = DataUtils.get_xy(data.values, 9,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniform_length = DataUtils.get_max_len(X) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_length ##set as constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Quantum Yield'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, qy = DataUtils.get_xy(data.values, 9,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_map=DataUtils.load_wordmap_from_json('smiles_wordmap.json')\n",
    "X_numeric = DataUtils.numeric_encoding(x_list=X, word_map=word_map, uniform_length=uniform_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 279)\n",
      "(35, 279)\n",
      "(138, 1)\n",
      "(35, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = DataUtils.splitData(x=X_numeric, y=qy, ratio=0.2)\n",
    "y_train = np.reshape(y_train, (-1, 1))\n",
    "y_test = np.reshape(y_test, (-1, 1))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, min_lr=1e-9, verbose=1, mode='auto',cooldown=0),\n",
    "    ModelCheckpoint(filepath=\"weights.qy_best.hdf5\", monitor='val_loss', save_best_only=True, verbose=1, mode='auto')    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_map), hidden_size, input_length=uniform_length))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(hidden_size, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[ModelUtils.coeff_determination, lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 138 samples, validate on 35 samples\n",
      "Epoch 1/150\n",
      "138/138 [==============================] - 11s 82ms/step - loss: 0.1308 - coeff_determination: -0.4970 - lr: 1.0000e-04 - val_loss: 0.0795 - val_coeff_determination: -0.0651 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07950, saving model to weights.qy_best.hdf5\n",
      "Epoch 2/150\n",
      "138/138 [==============================] - 7s 48ms/step - loss: 0.0921 - coeff_determination: -0.1042 - lr: 1.0000e-04 - val_loss: 0.0712 - val_coeff_determination: 0.0471 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07950 to 0.07121, saving model to weights.qy_best.hdf5\n",
      "Epoch 3/150\n",
      "138/138 [==============================] - 6s 46ms/step - loss: 0.0937 - coeff_determination: -0.0900 - lr: 1.0000e-04 - val_loss: 0.0757 - val_coeff_determination: -0.0129 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07121\n",
      "Epoch 4/150\n",
      "138/138 [==============================] - 7s 48ms/step - loss: 0.0940 - coeff_determination: -0.0519 - lr: 1.0000e-04 - val_loss: 0.0696 - val_coeff_determination: 0.0682 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07121 to 0.06961, saving model to weights.qy_best.hdf5\n",
      "Epoch 5/150\n",
      "138/138 [==============================] - 7s 47ms/step - loss: 0.0846 - coeff_determination: -0.0477 - lr: 1.0000e-04 - val_loss: 0.0705 - val_coeff_determination: 0.0554 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06961\n",
      "Epoch 6/150\n",
      "138/138 [==============================] - 7s 50ms/step - loss: 0.0878 - coeff_determination: -0.0052 - lr: 1.0000e-04 - val_loss: 0.0717 - val_coeff_determination: 0.0394 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06961\n",
      "Epoch 7/150\n",
      "138/138 [==============================] - 7s 52ms/step - loss: 0.0874 - coeff_determination: 0.0157 - lr: 1.0000e-04 - val_loss: 0.0700 - val_coeff_determination: 0.0620 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06961\n",
      "Epoch 8/150\n",
      "138/138 [==============================] - 8s 56ms/step - loss: 0.0823 - coeff_determination: -0.0800 - lr: 1.0000e-04 - val_loss: 0.0681 - val_coeff_determination: 0.0877 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06961 to 0.06813, saving model to weights.qy_best.hdf5\n",
      "Epoch 9/150\n",
      "138/138 [==============================] - 6s 45ms/step - loss: 0.0825 - coeff_determination: 0.0299 - lr: 1.0000e-04 - val_loss: 0.0678 - val_coeff_determination: 0.0924 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.06813 to 0.06777, saving model to weights.qy_best.hdf5\n",
      "Epoch 10/150\n",
      "138/138 [==============================] - 6s 44ms/step - loss: 0.0835 - coeff_determination: 0.0089 - lr: 1.0000e-04 - val_loss: 0.0674 - val_coeff_determination: 0.0970 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.06777 to 0.06742, saving model to weights.qy_best.hdf5\n",
      "Epoch 11/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0807 - coeff_determination: 0.0476 - lr: 1.0000e-04 - val_loss: 0.0675 - val_coeff_determination: 0.0966 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06742\n",
      "Epoch 12/150\n",
      "138/138 [==============================] - 6s 43ms/step - loss: 0.0801 - coeff_determination: 0.0827 - lr: 1.0000e-04 - val_loss: 0.0669 - val_coeff_determination: 0.1045 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.06742 to 0.06686, saving model to weights.qy_best.hdf5\n",
      "Epoch 13/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0788 - coeff_determination: 0.0926 - lr: 1.0000e-04 - val_loss: 0.0668 - val_coeff_determination: 0.1051 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06686 to 0.06682, saving model to weights.qy_best.hdf5\n",
      "Epoch 14/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0798 - coeff_determination: 0.0824 - lr: 1.0000e-04 - val_loss: 0.0663 - val_coeff_determination: 0.1114 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06682 to 0.06634, saving model to weights.qy_best.hdf5\n",
      "Epoch 15/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0805 - coeff_determination: 8.4200e-05 - lr: 1.0000e-04 - val_loss: 0.0659 - val_coeff_determination: 0.1170 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06634 to 0.06592, saving model to weights.qy_best.hdf5\n",
      "Epoch 16/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0769 - coeff_determination: 0.1422 - lr: 1.0000e-04 - val_loss: 0.0663 - val_coeff_determination: 0.1116 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06592\n",
      "Epoch 17/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0788 - coeff_determination: 0.0843 - lr: 1.0000e-04 - val_loss: 0.0656 - val_coeff_determination: 0.1205 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.06592 to 0.06564, saving model to weights.qy_best.hdf5\n",
      "Epoch 18/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0770 - coeff_determination: 0.1250 - lr: 1.0000e-04 - val_loss: 0.0652 - val_coeff_determination: 0.1263 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06564 to 0.06522, saving model to weights.qy_best.hdf5\n",
      "Epoch 19/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0753 - coeff_determination: 0.1548 - lr: 1.0000e-04 - val_loss: 0.0650 - val_coeff_determination: 0.1290 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.06522 to 0.06500, saving model to weights.qy_best.hdf5\n",
      "Epoch 20/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0769 - coeff_determination: 0.1068 - lr: 1.0000e-04 - val_loss: 0.0648 - val_coeff_determination: 0.1323 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06500 to 0.06476, saving model to weights.qy_best.hdf5\n",
      "Epoch 21/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0791 - coeff_determination: 0.0200 - lr: 1.0000e-04 - val_loss: 0.0644 - val_coeff_determination: 0.1363 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.06476 to 0.06445, saving model to weights.qy_best.hdf5\n",
      "Epoch 22/150\n",
      "138/138 [==============================] - 6s 44ms/step - loss: 0.0784 - coeff_determination: 0.0602 - lr: 1.0000e-04 - val_loss: 0.0642 - val_coeff_determination: 0.1392 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.06445 to 0.06422, saving model to weights.qy_best.hdf5\n",
      "Epoch 23/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0721 - coeff_determination: 0.1123 - lr: 1.0000e-04 - val_loss: 0.0640 - val_coeff_determination: 0.1414 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.06422 to 0.06405, saving model to weights.qy_best.hdf5\n",
      "Epoch 24/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0762 - coeff_determination: 0.0981 - lr: 1.0000e-04 - val_loss: 0.0637 - val_coeff_determination: 0.1460 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06405 to 0.06370, saving model to weights.qy_best.hdf5\n",
      "Epoch 25/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0753 - coeff_determination: 0.1474 - lr: 1.0000e-04 - val_loss: 0.0636 - val_coeff_determination: 0.1470 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.06370 to 0.06363, saving model to weights.qy_best.hdf5\n",
      "Epoch 26/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0720 - coeff_determination: 0.1775 - lr: 1.0000e-04 - val_loss: 0.0634 - val_coeff_determination: 0.1501 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.06363 to 0.06340, saving model to weights.qy_best.hdf5\n",
      "Epoch 27/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0696 - coeff_determination: 0.1938 - lr: 1.0000e-04 - val_loss: 0.0627 - val_coeff_determination: 0.1599 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.06340 to 0.06268, saving model to weights.qy_best.hdf5\n",
      "Epoch 28/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0731 - coeff_determination: 0.1647 - lr: 1.0000e-04 - val_loss: 0.0620 - val_coeff_determination: 0.1686 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.06268 to 0.06204, saving model to weights.qy_best.hdf5\n",
      "Epoch 29/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 5s 39ms/step - loss: 0.0732 - coeff_determination: 0.1500 - lr: 1.0000e-04 - val_loss: 0.0613 - val_coeff_determination: 0.1789 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.06204 to 0.06127, saving model to weights.qy_best.hdf5\n",
      "Epoch 30/150\n",
      "138/138 [==============================] - 5s 39ms/step - loss: 0.0707 - coeff_determination: 0.1186 - lr: 1.0000e-04 - val_loss: 0.0625 - val_coeff_determination: 0.1619 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06127\n",
      "Epoch 31/150\n",
      "138/138 [==============================] - 6s 46ms/step - loss: 0.0695 - coeff_determination: 0.1979 - lr: 1.0000e-04 - val_loss: 0.0606 - val_coeff_determination: 0.1886 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.06127 to 0.06057, saving model to weights.qy_best.hdf5\n",
      "Epoch 32/150\n",
      "138/138 [==============================] - 7s 53ms/step - loss: 0.0689 - coeff_determination: 0.2108 - lr: 1.0000e-04 - val_loss: 0.0588 - val_coeff_determination: 0.2128 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.06057 to 0.05876, saving model to weights.qy_best.hdf5\n",
      "Epoch 33/150\n",
      "138/138 [==============================] - 6s 46ms/step - loss: 0.0676 - coeff_determination: 0.2216 - lr: 1.0000e-04 - val_loss: 0.0578 - val_coeff_determination: 0.2254 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.05876 to 0.05783, saving model to weights.qy_best.hdf5\n",
      "Epoch 34/150\n",
      "138/138 [==============================] - 7s 48ms/step - loss: 0.0670 - coeff_determination: 0.2321 - lr: 1.0000e-04 - val_loss: 0.0572 - val_coeff_determination: 0.2340 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.05783 to 0.05719, saving model to weights.qy_best.hdf5\n",
      "Epoch 35/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0662 - coeff_determination: 0.1880 - lr: 1.0000e-04 - val_loss: 0.0569 - val_coeff_determination: 0.2372 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.05719 to 0.05694, saving model to weights.qy_best.hdf5\n",
      "Epoch 36/150\n",
      "138/138 [==============================] - 5s 40ms/step - loss: 0.0652 - coeff_determination: 0.2582 - lr: 1.0000e-04 - val_loss: 0.0552 - val_coeff_determination: 0.2608 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.05694 to 0.05519, saving model to weights.qy_best.hdf5\n",
      "Epoch 37/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0633 - coeff_determination: 0.2786 - lr: 1.0000e-04 - val_loss: 0.0543 - val_coeff_determination: 0.2728 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.05519 to 0.05428, saving model to weights.qy_best.hdf5\n",
      "Epoch 38/150\n",
      "138/138 [==============================] - 5s 40ms/step - loss: 0.0638 - coeff_determination: 0.2813 - lr: 1.0000e-04 - val_loss: 0.0535 - val_coeff_determination: 0.2839 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.05428 to 0.05347, saving model to weights.qy_best.hdf5\n",
      "Epoch 39/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0637 - coeff_determination: 0.2760 - lr: 1.0000e-04 - val_loss: 0.0534 - val_coeff_determination: 0.2862 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.05347 to 0.05336, saving model to weights.qy_best.hdf5\n",
      "Epoch 40/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0619 - coeff_determination: 0.3044 - lr: 1.0000e-04 - val_loss: 0.0524 - val_coeff_determination: 0.2991 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.05336 to 0.05243, saving model to weights.qy_best.hdf5\n",
      "Epoch 41/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0616 - coeff_determination: 0.2828 - lr: 1.0000e-04 - val_loss: 0.0516 - val_coeff_determination: 0.3099 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.05243 to 0.05163, saving model to weights.qy_best.hdf5\n",
      "Epoch 42/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0593 - coeff_determination: 0.3172 - lr: 1.0000e-04 - val_loss: 0.0514 - val_coeff_determination: 0.3131 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.05163 to 0.05141, saving model to weights.qy_best.hdf5\n",
      "Epoch 43/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0558 - coeff_determination: 0.2998 - lr: 1.0000e-04 - val_loss: 0.0495 - val_coeff_determination: 0.3383 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.05141 to 0.04949, saving model to weights.qy_best.hdf5\n",
      "Epoch 44/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0540 - coeff_determination: 0.3727 - lr: 1.0000e-04 - val_loss: 0.0486 - val_coeff_determination: 0.3498 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.04949 to 0.04861, saving model to weights.qy_best.hdf5\n",
      "Epoch 45/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0540 - coeff_determination: 0.3663 - lr: 1.0000e-04 - val_loss: 0.0481 - val_coeff_determination: 0.3565 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.04861 to 0.04814, saving model to weights.qy_best.hdf5\n",
      "Epoch 46/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0568 - coeff_determination: 0.3057 - lr: 1.0000e-04 - val_loss: 0.0473 - val_coeff_determination: 0.3677 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.04814 to 0.04733, saving model to weights.qy_best.hdf5\n",
      "Epoch 47/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0522 - coeff_determination: 0.3882 - lr: 1.0000e-04 - val_loss: 0.0466 - val_coeff_determination: 0.3772 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.04733 to 0.04664, saving model to weights.qy_best.hdf5\n",
      "Epoch 48/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0555 - coeff_determination: 0.3681 - lr: 1.0000e-04 - val_loss: 0.0472 - val_coeff_determination: 0.3706 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04664\n",
      "Epoch 49/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0550 - coeff_determination: 0.3518 - lr: 1.0000e-04 - val_loss: 0.0459 - val_coeff_determination: 0.3880 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.04664 to 0.04589, saving model to weights.qy_best.hdf5\n",
      "Epoch 50/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0517 - coeff_determination: 0.3845 - lr: 1.0000e-04 - val_loss: 0.0449 - val_coeff_determination: 0.4007 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.04589 to 0.04494, saving model to weights.qy_best.hdf5\n",
      "Epoch 51/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0531 - coeff_determination: 0.3815 - lr: 1.0000e-04 - val_loss: 0.0442 - val_coeff_determination: 0.4107 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.04494 to 0.04419, saving model to weights.qy_best.hdf5\n",
      "Epoch 52/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0477 - coeff_determination: 0.4282 - lr: 1.0000e-04 - val_loss: 0.0471 - val_coeff_determination: 0.3726 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.04419\n",
      "Epoch 53/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0525 - coeff_determination: 0.4026 - lr: 1.0000e-04 - val_loss: 0.0490 - val_coeff_determination: 0.3482 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04419\n",
      "Epoch 54/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0499 - coeff_determination: 0.4074 - lr: 1.0000e-04 - val_loss: 0.0477 - val_coeff_determination: 0.3659 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04419\n",
      "Epoch 55/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0493 - coeff_determination: 0.4113 - lr: 1.0000e-04 - val_loss: 0.0432 - val_coeff_determination: 0.4235 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.04419 to 0.04319, saving model to weights.qy_best.hdf5\n",
      "Epoch 56/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0465 - coeff_determination: 0.4587 - lr: 1.0000e-04 - val_loss: 0.0436 - val_coeff_determination: 0.4179 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.04319\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 6s 43ms/step - loss: 0.0443 - coeff_determination: 0.4942 - lr: 1.0000e-04 - val_loss: 0.0432 - val_coeff_determination: 0.4229 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04319\n",
      "Epoch 58/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0470 - coeff_determination: 0.4588 - lr: 1.0000e-04 - val_loss: 0.0452 - val_coeff_determination: 0.3971 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.04319\n",
      "Epoch 59/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0468 - coeff_determination: 0.4532 - lr: 1.0000e-04 - val_loss: 0.0451 - val_coeff_determination: 0.3990 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04319\n",
      "Epoch 60/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0459 - coeff_determination: 0.4650 - lr: 1.0000e-04 - val_loss: 0.0456 - val_coeff_determination: 0.3932 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04319\n",
      "Epoch 61/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0451 - coeff_determination: 0.4640 - lr: 1.0000e-04 - val_loss: 0.0468 - val_coeff_determination: 0.3776 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.04319\n",
      "Epoch 62/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0471 - coeff_determination: 0.4436 - lr: 1.0000e-04 - val_loss: 0.0471 - val_coeff_determination: 0.3734 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.04319\n",
      "Epoch 63/150\n",
      "138/138 [==============================] - 6s 43ms/step - loss: 0.0443 - coeff_determination: 0.4540 - lr: 1.0000e-04 - val_loss: 0.0452 - val_coeff_determination: 0.3975 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.04319\n",
      "Epoch 64/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0410 - coeff_determination: 0.5245 - lr: 1.0000e-04 - val_loss: 0.0477 - val_coeff_determination: 0.3652 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.04319\n",
      "Epoch 65/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0399 - coeff_determination: 0.4960 - lr: 1.0000e-04 - val_loss: 0.0503 - val_coeff_determination: 0.3313 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.04319\n",
      "Epoch 66/150\n",
      "138/138 [==============================] - 6s 46ms/step - loss: 0.0443 - coeff_determination: 0.4739 - lr: 1.0000e-04 - val_loss: 0.0522 - val_coeff_determination: 0.3066 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.04319\n",
      "Epoch 67/150\n",
      "138/138 [==============================] - 6s 47ms/step - loss: 0.0427 - coeff_determination: 0.5132 - lr: 1.0000e-04 - val_loss: 0.0504 - val_coeff_determination: 0.3308 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.04319\n",
      "Epoch 68/150\n",
      "138/138 [==============================] - 6s 47ms/step - loss: 0.0388 - coeff_determination: 0.5521 - lr: 1.0000e-04 - val_loss: 0.0479 - val_coeff_determination: 0.3620 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.04319\n",
      "Epoch 69/150\n",
      "138/138 [==============================] - 6s 45ms/step - loss: 0.0426 - coeff_determination: 0.5061 - lr: 1.0000e-04 - val_loss: 0.0485 - val_coeff_determination: 0.3541 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.04319\n",
      "Epoch 70/150\n",
      "138/138 [==============================] - 6s 45ms/step - loss: 0.0420 - coeff_determination: 0.4815 - lr: 1.0000e-04 - val_loss: 0.0502 - val_coeff_determination: 0.3331 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.04319\n",
      "Epoch 71/150\n",
      "138/138 [==============================] - 6s 45ms/step - loss: 0.0406 - coeff_determination: 0.5508 - lr: 1.0000e-04 - val_loss: 0.0511 - val_coeff_determination: 0.3208 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.04319\n",
      "Epoch 72/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0430 - coeff_determination: 0.4613 - lr: 1.0000e-04 - val_loss: 0.0487 - val_coeff_determination: 0.3513 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.04319\n",
      "Epoch 73/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0385 - coeff_determination: 0.5426 - lr: 1.0000e-04 - val_loss: 0.0473 - val_coeff_determination: 0.3705 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.04319\n",
      "Epoch 74/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0385 - coeff_determination: 0.5542 - lr: 1.0000e-04 - val_loss: 0.0482 - val_coeff_determination: 0.3588 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.04319\n",
      "Epoch 75/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0403 - coeff_determination: 0.5294 - lr: 1.0000e-04 - val_loss: 0.0547 - val_coeff_determination: 0.2728 - val_lr: 1.0000e-04\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.04319\n",
      "Epoch 76/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0393 - coeff_determination: 0.5428 - lr: 5.0000e-05 - val_loss: 0.0537 - val_coeff_determination: 0.2861 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.04319\n",
      "Epoch 77/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0376 - coeff_determination: 0.5359 - lr: 5.0000e-05 - val_loss: 0.0517 - val_coeff_determination: 0.3128 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.04319\n",
      "Epoch 78/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0363 - coeff_determination: 0.5766 - lr: 5.0000e-05 - val_loss: 0.0542 - val_coeff_determination: 0.2807 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.04319\n",
      "Epoch 79/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0372 - coeff_determination: 0.5320 - lr: 5.0000e-05 - val_loss: 0.0568 - val_coeff_determination: 0.2450 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04319\n",
      "Epoch 80/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0369 - coeff_determination: 0.5689 - lr: 5.0000e-05 - val_loss: 0.0523 - val_coeff_determination: 0.3058 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04319\n",
      "Epoch 81/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0375 - coeff_determination: 0.4955 - lr: 5.0000e-05 - val_loss: 0.0506 - val_coeff_determination: 0.3272 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04319\n",
      "Epoch 82/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0402 - coeff_determination: 0.5547 - lr: 5.0000e-05 - val_loss: 0.0538 - val_coeff_determination: 0.2857 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04319\n",
      "Epoch 83/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0358 - coeff_determination: 0.5802 - lr: 5.0000e-05 - val_loss: 0.0549 - val_coeff_determination: 0.2715 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04319\n",
      "Epoch 84/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0368 - coeff_determination: 0.5850 - lr: 5.0000e-05 - val_loss: 0.0548 - val_coeff_determination: 0.2719 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04319\n",
      "Epoch 85/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0379 - coeff_determination: 0.5608 - lr: 5.0000e-05 - val_loss: 0.0541 - val_coeff_determination: 0.2807 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04319\n",
      "Epoch 86/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0401 - coeff_determination: 0.5087 - lr: 5.0000e-05 - val_loss: 0.0516 - val_coeff_determination: 0.3149 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04319\n",
      "Epoch 87/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0346 - coeff_determination: 0.5270 - lr: 5.0000e-05 - val_loss: 0.0506 - val_coeff_determination: 0.3281 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04319\n",
      "Epoch 88/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0366 - coeff_determination: 0.5808 - lr: 5.0000e-05 - val_loss: 0.0554 - val_coeff_determination: 0.2631 - val_lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04319\n",
      "Epoch 89/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0358 - coeff_determination: 0.5956 - lr: 5.0000e-05 - val_loss: 0.0556 - val_coeff_determination: 0.2618 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04319\n",
      "Epoch 90/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0368 - coeff_determination: 0.5543 - lr: 5.0000e-05 - val_loss: 0.0545 - val_coeff_determination: 0.2769 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.04319\n",
      "Epoch 91/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0407 - coeff_determination: 0.5236 - lr: 5.0000e-05 - val_loss: 0.0550 - val_coeff_determination: 0.2691 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04319\n",
      "Epoch 92/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0349 - coeff_determination: 0.5118 - lr: 5.0000e-05 - val_loss: 0.0565 - val_coeff_determination: 0.2491 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04319\n",
      "Epoch 93/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0401 - coeff_determination: 0.5377 - lr: 5.0000e-05 - val_loss: 0.0564 - val_coeff_determination: 0.2506 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.04319\n",
      "Epoch 94/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0380 - coeff_determination: 0.5731 - lr: 5.0000e-05 - val_loss: 0.0505 - val_coeff_determination: 0.3282 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04319\n",
      "Epoch 95/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0361 - coeff_determination: 0.5889 - lr: 5.0000e-05 - val_loss: 0.0535 - val_coeff_determination: 0.2894 - val_lr: 5.0000e-05\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04319\n",
      "Epoch 96/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0351 - coeff_determination: 0.5999 - lr: 2.5000e-05 - val_loss: 0.0550 - val_coeff_determination: 0.2692 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04319\n",
      "Epoch 97/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0362 - coeff_determination: 0.5862 - lr: 2.5000e-05 - val_loss: 0.0563 - val_coeff_determination: 0.2522 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04319\n",
      "Epoch 98/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0335 - coeff_determination: 0.6028 - lr: 2.5000e-05 - val_loss: 0.0571 - val_coeff_determination: 0.2420 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04319\n",
      "Epoch 99/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0331 - coeff_determination: 0.6078 - lr: 2.5000e-05 - val_loss: 0.0591 - val_coeff_determination: 0.2148 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04319\n",
      "Epoch 100/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0327 - coeff_determination: 0.6208 - lr: 2.5000e-05 - val_loss: 0.0604 - val_coeff_determination: 0.1985 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04319\n",
      "Epoch 101/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0371 - coeff_determination: 0.5663 - lr: 2.5000e-05 - val_loss: 0.0601 - val_coeff_determination: 0.2023 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04319\n",
      "Epoch 102/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0363 - coeff_determination: 0.5568 - lr: 2.5000e-05 - val_loss: 0.0579 - val_coeff_determination: 0.2311 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04319\n",
      "Epoch 103/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0372 - coeff_determination: 0.5407 - lr: 2.5000e-05 - val_loss: 0.0557 - val_coeff_determination: 0.2608 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04319\n",
      "Epoch 104/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0344 - coeff_determination: 0.5656 - lr: 2.5000e-05 - val_loss: 0.0550 - val_coeff_determination: 0.2690 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04319\n",
      "Epoch 105/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0327 - coeff_determination: 0.6148 - lr: 2.5000e-05 - val_loss: 0.0551 - val_coeff_determination: 0.2680 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04319\n",
      "Epoch 106/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0341 - coeff_determination: 0.6063 - lr: 2.5000e-05 - val_loss: 0.0568 - val_coeff_determination: 0.2453 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04319\n",
      "Epoch 107/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0361 - coeff_determination: 0.5769 - lr: 2.5000e-05 - val_loss: 0.0579 - val_coeff_determination: 0.2308 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04319\n",
      "Epoch 108/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0356 - coeff_determination: 0.5491 - lr: 2.5000e-05 - val_loss: 0.0572 - val_coeff_determination: 0.2396 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04319\n",
      "Epoch 109/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0341 - coeff_determination: 0.5818 - lr: 2.5000e-05 - val_loss: 0.0566 - val_coeff_determination: 0.2486 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04319\n",
      "Epoch 110/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0342 - coeff_determination: 0.6054 - lr: 2.5000e-05 - val_loss: 0.0560 - val_coeff_determination: 0.2566 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04319\n",
      "Epoch 111/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0355 - coeff_determination: 0.5925 - lr: 2.5000e-05 - val_loss: 0.0575 - val_coeff_determination: 0.2363 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04319\n",
      "Epoch 112/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0327 - coeff_determination: 0.6153 - lr: 2.5000e-05 - val_loss: 0.0591 - val_coeff_determination: 0.2150 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04319\n",
      "Epoch 113/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0336 - coeff_determination: 0.6202 - lr: 2.5000e-05 - val_loss: 0.0591 - val_coeff_determination: 0.2146 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04319\n",
      "Epoch 114/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0320 - coeff_determination: 0.6387 - lr: 2.5000e-05 - val_loss: 0.0591 - val_coeff_determination: 0.2152 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.04319\n",
      "Epoch 115/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0346 - coeff_determination: 0.5878 - lr: 2.5000e-05 - val_loss: 0.0578 - val_coeff_determination: 0.2323 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04319\n",
      "Epoch 116/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0314 - coeff_determination: 0.6291 - lr: 1.2500e-05 - val_loss: 0.0577 - val_coeff_determination: 0.2336 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.04319\n",
      "Epoch 117/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0362 - coeff_determination: 0.5612 - lr: 1.2500e-05 - val_loss: 0.0593 - val_coeff_determination: 0.2122 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.04319\n",
      "Epoch 118/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0338 - coeff_determination: 0.5979 - lr: 1.2500e-05 - val_loss: 0.0604 - val_coeff_determination: 0.1970 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.04319\n",
      "Epoch 119/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0326 - coeff_determination: 0.5887 - lr: 1.2500e-05 - val_loss: 0.0605 - val_coeff_determination: 0.1970 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.04319\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0334 - coeff_determination: 0.6110 - lr: 1.2500e-05 - val_loss: 0.0597 - val_coeff_determination: 0.2067 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.04319\n",
      "Epoch 121/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0327 - coeff_determination: 0.6187 - lr: 1.2500e-05 - val_loss: 0.0590 - val_coeff_determination: 0.2163 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.04319\n",
      "Epoch 122/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0351 - coeff_determination: 0.5892 - lr: 1.2500e-05 - val_loss: 0.0600 - val_coeff_determination: 0.2030 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.04319\n",
      "Epoch 123/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0330 - coeff_determination: 0.5265 - lr: 1.2500e-05 - val_loss: 0.0615 - val_coeff_determination: 0.1829 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.04319\n",
      "Epoch 124/150\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0329 - coeff_determination: 0.6235 - lr: 1.2500e-05 - val_loss: 0.0625 - val_coeff_determination: 0.1695 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.04319\n",
      "Epoch 125/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0328 - coeff_determination: 0.5557 - lr: 1.2500e-05 - val_loss: 0.0620 - val_coeff_determination: 0.1770 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.04319\n",
      "Epoch 126/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0342 - coeff_determination: 0.3310 - lr: 1.2500e-05 - val_loss: 0.0612 - val_coeff_determination: 0.1873 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.04319\n",
      "Epoch 127/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0348 - coeff_determination: 0.5985 - lr: 1.2500e-05 - val_loss: 0.0609 - val_coeff_determination: 0.1911 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.04319\n",
      "Epoch 128/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0336 - coeff_determination: 0.6211 - lr: 1.2500e-05 - val_loss: 0.0614 - val_coeff_determination: 0.1850 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04319\n",
      "Epoch 129/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0347 - coeff_determination: 0.5918 - lr: 1.2500e-05 - val_loss: 0.0617 - val_coeff_determination: 0.1809 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.04319\n",
      "Epoch 130/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0341 - coeff_determination: 0.6142 - lr: 1.2500e-05 - val_loss: 0.0625 - val_coeff_determination: 0.1697 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.04319\n",
      "Epoch 131/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0333 - coeff_determination: 0.6218 - lr: 1.2500e-05 - val_loss: 0.0627 - val_coeff_determination: 0.1671 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.04319\n",
      "Epoch 132/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0350 - coeff_determination: 0.5896 - lr: 1.2500e-05 - val_loss: 0.0630 - val_coeff_determination: 0.1639 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.04319\n",
      "Epoch 133/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0354 - coeff_determination: 0.2927 - lr: 1.2500e-05 - val_loss: 0.0623 - val_coeff_determination: 0.1727 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04319\n",
      "Epoch 134/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0335 - coeff_determination: 0.5957 - lr: 1.2500e-05 - val_loss: 0.0632 - val_coeff_determination: 0.1611 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.04319\n",
      "Epoch 135/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0328 - coeff_determination: 0.6197 - lr: 1.2500e-05 - val_loss: 0.0636 - val_coeff_determination: 0.1548 - val_lr: 1.2500e-05\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04319\n",
      "Epoch 136/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0337 - coeff_determination: 0.5957 - lr: 6.2500e-06 - val_loss: 0.0636 - val_coeff_determination: 0.1557 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04319\n",
      "Epoch 137/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0338 - coeff_determination: 0.6204 - lr: 6.2500e-06 - val_loss: 0.0631 - val_coeff_determination: 0.1614 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.04319\n",
      "Epoch 138/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0323 - coeff_determination: 0.5733 - lr: 6.2500e-06 - val_loss: 0.0632 - val_coeff_determination: 0.1600 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04319\n",
      "Epoch 139/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0343 - coeff_determination: 0.6177 - lr: 6.2500e-06 - val_loss: 0.0633 - val_coeff_determination: 0.1593 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04319\n",
      "Epoch 140/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0319 - coeff_determination: 0.5976 - lr: 6.2500e-06 - val_loss: 0.0633 - val_coeff_determination: 0.1594 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04319\n",
      "Epoch 141/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0332 - coeff_determination: 0.6235 - lr: 6.2500e-06 - val_loss: 0.0626 - val_coeff_determination: 0.1680 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04319\n",
      "Epoch 142/150\n",
      "138/138 [==============================] - 6s 43ms/step - loss: 0.0329 - coeff_determination: 0.6095 - lr: 6.2500e-06 - val_loss: 0.0620 - val_coeff_determination: 0.1767 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.04319\n",
      "Epoch 143/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0350 - coeff_determination: 0.6001 - lr: 6.2500e-06 - val_loss: 0.0614 - val_coeff_determination: 0.1847 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.04319\n",
      "Epoch 144/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0342 - coeff_determination: 0.5965 - lr: 6.2500e-06 - val_loss: 0.0615 - val_coeff_determination: 0.1836 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.04319\n",
      "Epoch 145/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0330 - coeff_determination: 0.5688 - lr: 6.2500e-06 - val_loss: 0.0619 - val_coeff_determination: 0.1777 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.04319\n",
      "Epoch 146/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0302 - coeff_determination: 0.6545 - lr: 6.2500e-06 - val_loss: 0.0624 - val_coeff_determination: 0.1711 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.04319\n",
      "Epoch 147/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0328 - coeff_determination: 0.6176 - lr: 6.2500e-06 - val_loss: 0.0630 - val_coeff_determination: 0.1636 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.04319\n",
      "Epoch 148/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0362 - coeff_determination: 0.2481 - lr: 6.2500e-06 - val_loss: 0.0634 - val_coeff_determination: 0.1586 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.04319\n",
      "Epoch 149/150\n",
      "138/138 [==============================] - 6s 42ms/step - loss: 0.0312 - coeff_determination: 0.6205 - lr: 6.2500e-06 - val_loss: 0.0633 - val_coeff_determination: 0.1588 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04319\n",
      "Epoch 150/150\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0327 - coeff_determination: 0.6238 - lr: 6.2500e-06 - val_loss: 0.0632 - val_coeff_determination: 0.1605 - val_lr: 6.2500e-06\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.04319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a62087470>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=32, validation_data=[X_test, y_test], callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_lstm_qy.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('model_lstm_qy.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('weights.qy_best.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(loaded_model,to_file='lstm_qy_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.488134927569042"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_train, loaded_model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4229403361884645"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, loaded_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_error(x_train, x_test, y_train, y_test, model, save_fig_fname, label):\n",
    "        \"\"\"\n",
    "        input model and actual data, plot train, test predicted data and error\n",
    "        \"\"\"\n",
    "        y_train = y_train.reshape(-1,1)\n",
    "        y_test = y_test.reshape(-1,1)\n",
    "    \n",
    "        plt.figure(figsize=(8, 10), dpi=100)\n",
    "        plt.subplot(211)\n",
    "        plt.scatter(y_train, model.predict(X_train), color = 'r', label = 'train')\n",
    "        plt.scatter(y_test, model.predict(X_test), color = 'blue', label = 'test')\n",
    "        plt.xlabel('Actual %s'%label, fontsize=12)\n",
    "        plt.ylabel('Predicted %s'%label, fontsize=12)\n",
    "        plt.legend(loc='upper center')\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.scatter(y_train, model.predict(X_train)-y_train, color = 'r', label = 'train', marker= 'x')\n",
    "        plt.scatter(y_test, model.predict(X_test)-y_test, color = 'blue', label = 'test', marker = 'x')\n",
    "        plt.axhline(0, ls='--')\n",
    "        plt.xlabel('Actual %s'%label, fontsize=12)\n",
    "        plt.ylabel('Prediction error(nm)', fontsize=12)\n",
    "        plt.legend(loc='upper center')\n",
    "        \n",
    "        if save_fig_fname is not None:\n",
    "            plt.savefig(save_fig_fname)\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAM2CAYAAAATpI5cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 800x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_error(X_train,X_test,y_train,y_test, loaded_model, None, 'epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model on the quantum yield (not good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([56., 34., 20., 11., 11.,  9., 12.,  2.,  6., 12.]),\n",
       " array([4.0000e-04, 1.0036e-01, 2.0032e-01, 3.0028e-01, 4.0024e-01,\n",
       "        5.0020e-01, 6.0016e-01, 7.0012e-01, 8.0008e-01, 9.0004e-01,\n",
       "        1.0000e+00]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(qy.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 279, 50)           2100      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 279, 50)           200       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 273, 192)          67392     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 273, 192)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 269, 192)          184512    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 269, 192)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 267, 192)          110784    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 267, 192)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 51264)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               5126500   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,491,589\n",
      "Trainable params: 5,491,489\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_map), 50, input_length=uniform_length))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(192,7,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv1D(192,5,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv1D(192,3,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, min_lr=1e-10, verbose=1, mode='auto',cooldown=0),\n",
    "    ModelCheckpoint(filepath=\"weights.qy_cnn_best.hdf5\", monitor='val_loss', save_best_only=True, verbose=1, mode='auto')    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.000005)\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[ModelUtils.coeff_determination, lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 138 samples, validate on 35 samples\n",
      "Epoch 1/150\n",
      "138/138 [==============================] - 4s 29ms/step - loss: 0.1994 - coeff_determination: -1.6292 - lr: 5.0000e-06 - val_loss: 0.0864 - val_coeff_determination: -0.1536 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08639, saving model to weights.qy_cnn_best.hdf5\n",
      "Epoch 2/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.2252 - coeff_determination: -1.6628 - lr: 5.0000e-06 - val_loss: 0.0798 - val_coeff_determination: -0.0658 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08639 to 0.07982, saving model to weights.qy_cnn_best.hdf5\n",
      "Epoch 3/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1559 - coeff_determination: -1.3318 - lr: 5.0000e-06 - val_loss: 0.0823 - val_coeff_determination: -0.0999 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07982\n",
      "Epoch 4/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1653 - coeff_determination: -1.0302 - lr: 5.0000e-06 - val_loss: 0.0897 - val_coeff_determination: -0.1989 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07982\n",
      "Epoch 5/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1575 - coeff_determination: -0.7880 - lr: 5.0000e-06 - val_loss: 0.0965 - val_coeff_determination: -0.2903 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07982\n",
      "Epoch 6/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1820 - coeff_determination: -1.0531 - lr: 5.0000e-06 - val_loss: 0.0935 - val_coeff_determination: -0.2503 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07982\n",
      "Epoch 7/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.2011 - coeff_determination: -1.3254 - lr: 5.0000e-06 - val_loss: 0.0904 - val_coeff_determination: -0.2088 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07982\n",
      "Epoch 8/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1911 - coeff_determination: -1.2428 - lr: 5.0000e-06 - val_loss: 0.0854 - val_coeff_determination: -0.1404 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07982\n",
      "Epoch 9/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1425 - coeff_determination: -0.6727 - lr: 5.0000e-06 - val_loss: 0.0860 - val_coeff_determination: -0.1494 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07982\n",
      "Epoch 10/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1550 - coeff_determination: -1.1981 - lr: 5.0000e-06 - val_loss: 0.0878 - val_coeff_determination: -0.1732 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07982\n",
      "Epoch 11/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1399 - coeff_determination: -0.6953 - lr: 5.0000e-06 - val_loss: 0.0918 - val_coeff_determination: -0.2281 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.07982\n",
      "Epoch 12/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1430 - coeff_determination: -0.7403 - lr: 5.0000e-06 - val_loss: 0.0946 - val_coeff_determination: -0.2653 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.07982\n",
      "Epoch 13/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1580 - coeff_determination: -0.7578 - lr: 5.0000e-06 - val_loss: 0.0924 - val_coeff_determination: -0.2358 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.07982\n",
      "Epoch 14/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1511 - coeff_determination: -0.7891 - lr: 5.0000e-06 - val_loss: 0.0892 - val_coeff_determination: -0.1932 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.07982\n",
      "Epoch 15/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1252 - coeff_determination: -0.4517 - lr: 5.0000e-06 - val_loss: 0.0862 - val_coeff_determination: -0.1528 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.07982\n",
      "Epoch 16/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1187 - coeff_determination: -0.3819 - lr: 5.0000e-06 - val_loss: 0.0857 - val_coeff_determination: -0.1466 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.07982\n",
      "Epoch 17/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1325 - coeff_determination: -0.6662 - lr: 5.0000e-06 - val_loss: 0.0890 - val_coeff_determination: -0.1900 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.07982\n",
      "Epoch 18/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1307 - coeff_determination: -0.4856 - lr: 5.0000e-06 - val_loss: 0.0915 - val_coeff_determination: -0.2235 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.07982\n",
      "Epoch 19/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1107 - coeff_determination: -0.2370 - lr: 5.0000e-06 - val_loss: 0.0951 - val_coeff_determination: -0.2718 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07982\n",
      "Epoch 20/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1070 - coeff_determination: -0.3512 - lr: 5.0000e-06 - val_loss: 0.0965 - val_coeff_determination: -0.2908 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07982\n",
      "Epoch 21/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1003 - coeff_determination: -0.2403 - lr: 5.0000e-06 - val_loss: 0.0944 - val_coeff_determination: -0.2638 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.07982\n",
      "Epoch 22/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1203 - coeff_determination: -0.3370 - lr: 5.0000e-06 - val_loss: 0.0943 - val_coeff_determination: -0.2613 - val_lr: 5.0000e-06\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07982\n",
      "Epoch 23/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1002 - coeff_determination: -0.1194 - lr: 2.5000e-06 - val_loss: 0.0948 - val_coeff_determination: -0.2689 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.07982\n",
      "Epoch 24/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1366 - coeff_determination: -0.5519 - lr: 2.5000e-06 - val_loss: 0.0944 - val_coeff_determination: -0.2632 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07982\n",
      "Epoch 25/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1349 - coeff_determination: -0.6507 - lr: 2.5000e-06 - val_loss: 0.0953 - val_coeff_determination: -0.2751 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.07982\n",
      "Epoch 26/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1229 - coeff_determination: -0.4577 - lr: 2.5000e-06 - val_loss: 0.0959 - val_coeff_determination: -0.2835 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.07982\n",
      "Epoch 27/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1199 - coeff_determination: -0.4565 - lr: 2.5000e-06 - val_loss: 0.0960 - val_coeff_determination: -0.2853 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.07982\n",
      "Epoch 28/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1048 - coeff_determination: -0.1743 - lr: 2.5000e-06 - val_loss: 0.0959 - val_coeff_determination: -0.2841 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.07982\n",
      "Epoch 29/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1298 - coeff_determination: -0.7830 - lr: 2.5000e-06 - val_loss: 0.0947 - val_coeff_determination: -0.2676 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.07982\n",
      "Epoch 30/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1102 - coeff_determination: -0.2055 - lr: 2.5000e-06 - val_loss: 0.0940 - val_coeff_determination: -0.2583 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.07982\n",
      "Epoch 31/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1097 - coeff_determination: -0.3450 - lr: 2.5000e-06 - val_loss: 0.0934 - val_coeff_determination: -0.2499 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.07982\n",
      "Epoch 32/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1098 - coeff_determination: -0.2602 - lr: 2.5000e-06 - val_loss: 0.0935 - val_coeff_determination: -0.2518 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.07982\n",
      "Epoch 33/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0991 - coeff_determination: -0.1868 - lr: 2.5000e-06 - val_loss: 0.0935 - val_coeff_determination: -0.2523 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.07982\n",
      "Epoch 34/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1167 - coeff_determination: -0.3863 - lr: 2.5000e-06 - val_loss: 0.0938 - val_coeff_determination: -0.2552 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07982\n",
      "Epoch 35/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1220 - coeff_determination: -0.7371 - lr: 2.5000e-06 - val_loss: 0.0936 - val_coeff_determination: -0.2529 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07982\n",
      "Epoch 36/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1023 - coeff_determination: -0.2502 - lr: 2.5000e-06 - val_loss: 0.0942 - val_coeff_determination: -0.2613 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.07982\n",
      "Epoch 37/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1296 - coeff_determination: -0.4978 - lr: 2.5000e-06 - val_loss: 0.0941 - val_coeff_determination: -0.2599 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07982\n",
      "Epoch 38/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1009 - coeff_determination: -0.1329 - lr: 2.5000e-06 - val_loss: 0.0943 - val_coeff_determination: -0.2622 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07982\n",
      "Epoch 39/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1210 - coeff_determination: -0.4302 - lr: 2.5000e-06 - val_loss: 0.0937 - val_coeff_determination: -0.2550 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.07982\n",
      "Epoch 40/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0978 - coeff_determination: -0.1823 - lr: 2.5000e-06 - val_loss: 0.0945 - val_coeff_determination: -0.2650 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07982\n",
      "Epoch 41/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1073 - coeff_determination: -0.4570 - lr: 2.5000e-06 - val_loss: 0.0946 - val_coeff_determination: -0.2667 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.07982\n",
      "Epoch 42/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1180 - coeff_determination: -0.4222 - lr: 2.5000e-06 - val_loss: 0.0947 - val_coeff_determination: -0.2684 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07982\n",
      "Epoch 43/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1137 - coeff_determination: -0.3405 - lr: 1.2500e-06 - val_loss: 0.0947 - val_coeff_determination: -0.2686 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07982\n",
      "Epoch 44/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1124 - coeff_determination: -0.2734 - lr: 1.2500e-06 - val_loss: 0.0950 - val_coeff_determination: -0.2723 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07982\n",
      "Epoch 45/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1052 - coeff_determination: -0.2981 - lr: 1.2500e-06 - val_loss: 0.0949 - val_coeff_determination: -0.2706 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07982\n",
      "Epoch 46/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1120 - coeff_determination: -0.2560 - lr: 1.2500e-06 - val_loss: 0.0950 - val_coeff_determination: -0.2717 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07982\n",
      "Epoch 47/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0849 - coeff_determination: -0.0656 - lr: 1.2500e-06 - val_loss: 0.0951 - val_coeff_determination: -0.2729 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07982\n",
      "Epoch 48/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0962 - coeff_determination: -0.1369 - lr: 1.2500e-06 - val_loss: 0.0952 - val_coeff_determination: -0.2742 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.07982\n",
      "Epoch 49/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0951 - coeff_determination: -0.1004 - lr: 1.2500e-06 - val_loss: 0.0954 - val_coeff_determination: -0.2778 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07982\n",
      "Epoch 50/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0987 - coeff_determination: -0.1559 - lr: 1.2500e-06 - val_loss: 0.0956 - val_coeff_determination: -0.2802 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07982\n",
      "Epoch 51/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1194 - coeff_determination: -0.4486 - lr: 1.2500e-06 - val_loss: 0.0958 - val_coeff_determination: -0.2832 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.07982\n",
      "Epoch 52/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0941 - coeff_determination: -0.1186 - lr: 1.2500e-06 - val_loss: 0.0959 - val_coeff_determination: -0.2844 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.07982\n",
      "Epoch 53/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1044 - coeff_determination: -0.1898 - lr: 1.2500e-06 - val_loss: 0.0960 - val_coeff_determination: -0.2858 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.07982\n",
      "Epoch 54/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1076 - coeff_determination: -0.2157 - lr: 1.2500e-06 - val_loss: 0.0960 - val_coeff_determination: -0.2854 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.07982\n",
      "Epoch 55/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0977 - coeff_determination: -0.1221 - lr: 1.2500e-06 - val_loss: 0.0963 - val_coeff_determination: -0.2897 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.07982\n",
      "Epoch 56/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0918 - coeff_determination: -0.1428 - lr: 1.2500e-06 - val_loss: 0.0966 - val_coeff_determination: -0.2942 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.07982\n",
      "Epoch 57/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1058 - coeff_determination: -0.5616 - lr: 1.2500e-06 - val_loss: 0.0974 - val_coeff_determination: -0.3050 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.07982\n",
      "Epoch 58/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1142 - coeff_determination: -0.2945 - lr: 1.2500e-06 - val_loss: 0.0982 - val_coeff_determination: -0.3158 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.07982\n",
      "Epoch 59/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0948 - coeff_determination: -0.0854 - lr: 1.2500e-06 - val_loss: 0.0985 - val_coeff_determination: -0.3198 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.07982\n",
      "Epoch 60/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1104 - coeff_determination: -0.2655 - lr: 1.2500e-06 - val_loss: 0.0988 - val_coeff_determination: -0.3228 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.07982\n",
      "Epoch 61/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1063 - coeff_determination: -0.2136 - lr: 1.2500e-06 - val_loss: 0.0992 - val_coeff_determination: -0.3282 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.07982\n",
      "Epoch 62/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1117 - coeff_determination: -0.3142 - lr: 1.2500e-06 - val_loss: 0.0995 - val_coeff_determination: -0.3323 - val_lr: 1.2500e-06\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.07982\n",
      "Epoch 63/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1102 - coeff_determination: -0.2897 - lr: 6.2500e-07 - val_loss: 0.0994 - val_coeff_determination: -0.3319 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.07982\n",
      "Epoch 64/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1030 - coeff_determination: -0.2310 - lr: 6.2500e-07 - val_loss: 0.0992 - val_coeff_determination: -0.3292 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.07982\n",
      "Epoch 65/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1031 - coeff_determination: -0.3016 - lr: 6.2500e-07 - val_loss: 0.0992 - val_coeff_determination: -0.3288 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.07982\n",
      "Epoch 66/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1125 - coeff_determination: -0.2753 - lr: 6.2500e-07 - val_loss: 0.0993 - val_coeff_determination: -0.3296 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.07982\n",
      "Epoch 67/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0896 - coeff_determination: -0.1006 - lr: 6.2500e-07 - val_loss: 0.0993 - val_coeff_determination: -0.3296 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.07982\n",
      "Epoch 68/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1037 - coeff_determination: -0.2152 - lr: 6.2500e-07 - val_loss: 0.0991 - val_coeff_determination: -0.3272 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.07982\n",
      "Epoch 69/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0945 - coeff_determination: -0.1578 - lr: 6.2500e-07 - val_loss: 0.0990 - val_coeff_determination: -0.3262 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.07982\n",
      "Epoch 70/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1064 - coeff_determination: -0.2129 - lr: 6.2500e-07 - val_loss: 0.0989 - val_coeff_determination: -0.3246 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.07982\n",
      "Epoch 71/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0938 - coeff_determination: -0.0985 - lr: 6.2500e-07 - val_loss: 0.0989 - val_coeff_determination: -0.3250 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.07982\n",
      "Epoch 72/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1128 - coeff_determination: -0.3299 - lr: 6.2500e-07 - val_loss: 0.0989 - val_coeff_determination: -0.3251 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.07982\n",
      "Epoch 73/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1058 - coeff_determination: -0.1917 - lr: 6.2500e-07 - val_loss: 0.0989 - val_coeff_determination: -0.3245 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.07982\n",
      "Epoch 74/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0920 - coeff_determination: -0.0621 - lr: 6.2500e-07 - val_loss: 0.0987 - val_coeff_determination: -0.3217 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.07982\n",
      "Epoch 75/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1140 - coeff_determination: -0.4097 - lr: 6.2500e-07 - val_loss: 0.0985 - val_coeff_determination: -0.3198 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.07982\n",
      "Epoch 76/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0888 - coeff_determination: -0.0788 - lr: 6.2500e-07 - val_loss: 0.0985 - val_coeff_determination: -0.3188 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.07982\n",
      "Epoch 77/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1110 - coeff_determination: -0.3190 - lr: 6.2500e-07 - val_loss: 0.0984 - val_coeff_determination: -0.3179 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07982\n",
      "Epoch 78/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0900 - coeff_determination: -0.0408 - lr: 6.2500e-07 - val_loss: 0.0984 - val_coeff_determination: -0.3185 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.07982\n",
      "Epoch 79/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0934 - coeff_determination: -0.0921 - lr: 6.2500e-07 - val_loss: 0.0982 - val_coeff_determination: -0.3152 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07982\n",
      "Epoch 80/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1129 - coeff_determination: -0.3482 - lr: 6.2500e-07 - val_loss: 0.0981 - val_coeff_determination: -0.3138 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.07982\n",
      "Epoch 81/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1026 - coeff_determination: -0.2232 - lr: 6.2500e-07 - val_loss: 0.0979 - val_coeff_determination: -0.3114 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.07982\n",
      "Epoch 82/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0936 - coeff_determination: -0.0370 - lr: 6.2500e-07 - val_loss: 0.0977 - val_coeff_determination: -0.3092 - val_lr: 6.2500e-07\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.07982\n",
      "Epoch 83/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1037 - coeff_determination: -0.2091 - lr: 3.1250e-07 - val_loss: 0.0977 - val_coeff_determination: -0.3088 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.07982\n",
      "Epoch 84/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1151 - coeff_determination: -0.3339 - lr: 3.1250e-07 - val_loss: 0.0977 - val_coeff_determination: -0.3089 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.07982\n",
      "Epoch 85/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0983 - coeff_determination: -0.1205 - lr: 3.1250e-07 - val_loss: 0.0977 - val_coeff_determination: -0.3091 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.07982\n",
      "Epoch 86/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1137 - coeff_determination: -0.3502 - lr: 3.1250e-07 - val_loss: 0.0978 - val_coeff_determination: -0.3099 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.07982\n",
      "Epoch 87/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0968 - coeff_determination: -0.1997 - lr: 3.1250e-07 - val_loss: 0.0977 - val_coeff_determination: -0.3085 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.07982\n",
      "Epoch 88/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1050 - coeff_determination: -0.2228 - lr: 3.1250e-07 - val_loss: 0.0976 - val_coeff_determination: -0.3073 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.07982\n",
      "Epoch 89/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0982 - coeff_determination: -0.1414 - lr: 3.1250e-07 - val_loss: 0.0975 - val_coeff_determination: -0.3064 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.07982\n",
      "Epoch 90/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1143 - coeff_determination: -0.3611 - lr: 3.1250e-07 - val_loss: 0.0975 - val_coeff_determination: -0.3059 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.07982\n",
      "Epoch 91/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0893 - coeff_determination: -0.0509 - lr: 3.1250e-07 - val_loss: 0.0975 - val_coeff_determination: -0.3057 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.07982\n",
      "Epoch 92/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0843 - coeff_determination: 0.0195 - lr: 3.1250e-07 - val_loss: 0.0975 - val_coeff_determination: -0.3061 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.07982\n",
      "Epoch 93/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1037 - coeff_determination: -0.2094 - lr: 3.1250e-07 - val_loss: 0.0976 - val_coeff_determination: -0.3075 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.07982\n",
      "Epoch 94/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1016 - coeff_determination: -0.3066 - lr: 3.1250e-07 - val_loss: 0.0976 - val_coeff_determination: -0.3077 - val_lr: 3.1250e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00094: val_loss did not improve from 0.07982\n",
      "Epoch 95/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1159 - coeff_determination: -0.3714 - lr: 3.1250e-07 - val_loss: 0.0976 - val_coeff_determination: -0.3076 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.07982\n",
      "Epoch 96/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0967 - coeff_determination: -0.1310 - lr: 3.1250e-07 - val_loss: 0.0976 - val_coeff_determination: -0.3069 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.07982\n",
      "Epoch 97/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0988 - coeff_determination: -0.1752 - lr: 3.1250e-07 - val_loss: 0.0975 - val_coeff_determination: -0.3065 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.07982\n",
      "Epoch 98/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1081 - coeff_determination: -0.2358 - lr: 3.1250e-07 - val_loss: 0.0975 - val_coeff_determination: -0.3055 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.07982\n",
      "Epoch 99/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0883 - coeff_determination: 0.0057 - lr: 3.1250e-07 - val_loss: 0.0973 - val_coeff_determination: -0.3032 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.07982\n",
      "Epoch 100/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1041 - coeff_determination: -0.2628 - lr: 3.1250e-07 - val_loss: 0.0972 - val_coeff_determination: -0.3016 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.07982\n",
      "Epoch 101/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1095 - coeff_determination: -0.2622 - lr: 3.1250e-07 - val_loss: 0.0970 - val_coeff_determination: -0.2993 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.07982\n",
      "Epoch 102/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0963 - coeff_determination: -0.1427 - lr: 3.1250e-07 - val_loss: 0.0969 - val_coeff_determination: -0.2985 - val_lr: 3.1250e-07\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.07982\n",
      "Epoch 103/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1101 - coeff_determination: -0.4018 - lr: 1.5625e-07 - val_loss: 0.0969 - val_coeff_determination: -0.2978 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.07982\n",
      "Epoch 104/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0986 - coeff_determination: -0.1237 - lr: 1.5625e-07 - val_loss: 0.0969 - val_coeff_determination: -0.2982 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.07982\n",
      "Epoch 105/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1099 - coeff_determination: -0.2667 - lr: 1.5625e-07 - val_loss: 0.0970 - val_coeff_determination: -0.2997 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.07982\n",
      "Epoch 106/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0990 - coeff_determination: -0.1236 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3005 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.07982\n",
      "Epoch 107/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0925 - coeff_determination: -0.1596 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3007 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.07982\n",
      "Epoch 108/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1055 - coeff_determination: -0.2290 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3008 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.07982\n",
      "Epoch 109/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0968 - coeff_determination: -0.1579 - lr: 1.5625e-07 - val_loss: 0.0972 - val_coeff_determination: -0.3016 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.07982\n",
      "Epoch 110/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1001 - coeff_determination: -0.1635 - lr: 1.5625e-07 - val_loss: 0.0972 - val_coeff_determination: -0.3019 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.07982\n",
      "Epoch 111/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0974 - coeff_determination: -0.1373 - lr: 1.5625e-07 - val_loss: 0.0972 - val_coeff_determination: -0.3016 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.07982\n",
      "Epoch 112/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0885 - coeff_determination: -0.0897 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3010 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.07982\n",
      "Epoch 113/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1071 - coeff_determination: -0.2145 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3004 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.07982\n",
      "Epoch 114/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0920 - coeff_determination: -0.0799 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3000 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.07982\n",
      "Epoch 115/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0995 - coeff_determination: -0.1107 - lr: 1.5625e-07 - val_loss: 0.0970 - val_coeff_determination: -0.2995 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.07982\n",
      "Epoch 116/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0974 - coeff_determination: -0.1823 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3004 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.07982\n",
      "Epoch 117/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1049 - coeff_determination: -0.2179 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3002 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.07982\n",
      "Epoch 118/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1076 - coeff_determination: -0.3138 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3011 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.07982\n",
      "Epoch 119/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0851 - coeff_determination: -0.0869 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3010 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.07982\n",
      "Epoch 120/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0961 - coeff_determination: -0.1496 - lr: 1.5625e-07 - val_loss: 0.0971 - val_coeff_determination: -0.3004 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.07982\n",
      "Epoch 121/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0931 - coeff_determination: -0.1318 - lr: 1.5625e-07 - val_loss: 0.0972 - val_coeff_determination: -0.3015 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.07982\n",
      "Epoch 122/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1134 - coeff_determination: -0.4961 - lr: 1.5625e-07 - val_loss: 0.0972 - val_coeff_determination: -0.3022 - val_lr: 1.5625e-07\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.07982\n",
      "Epoch 123/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1037 - coeff_determination: -0.2511 - lr: 7.8125e-08 - val_loss: 0.0972 - val_coeff_determination: -0.3024 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.07982\n",
      "Epoch 124/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1006 - coeff_determination: -0.1964 - lr: 7.8125e-08 - val_loss: 0.0972 - val_coeff_determination: -0.3019 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.07982\n",
      "Epoch 125/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1035 - coeff_determination: -0.1841 - lr: 7.8125e-08 - val_loss: 0.0972 - val_coeff_determination: -0.3018 - val_lr: 7.8125e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00125: val_loss did not improve from 0.07982\n",
      "Epoch 126/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1046 - coeff_determination: -0.2160 - lr: 7.8125e-08 - val_loss: 0.0972 - val_coeff_determination: -0.3016 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.07982\n",
      "Epoch 127/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1083 - coeff_determination: -0.2225 - lr: 7.8125e-08 - val_loss: 0.0971 - val_coeff_determination: -0.3012 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.07982\n",
      "Epoch 128/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0944 - coeff_determination: -0.1526 - lr: 7.8125e-08 - val_loss: 0.0971 - val_coeff_determination: -0.3010 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.07982\n",
      "Epoch 129/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1055 - coeff_determination: -0.2041 - lr: 7.8125e-08 - val_loss: 0.0971 - val_coeff_determination: -0.3008 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.07982\n",
      "Epoch 130/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1108 - coeff_determination: -0.2909 - lr: 7.8125e-08 - val_loss: 0.0971 - val_coeff_determination: -0.3008 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.07982\n",
      "Epoch 131/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0853 - coeff_determination: -0.0822 - lr: 7.8125e-08 - val_loss: 0.0971 - val_coeff_determination: -0.3006 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.07982\n",
      "Epoch 132/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1159 - coeff_determination: -0.3444 - lr: 7.8125e-08 - val_loss: 0.0972 - val_coeff_determination: -0.3015 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.07982\n",
      "Epoch 133/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0922 - coeff_determination: -0.0835 - lr: 7.8125e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3027 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.07982\n",
      "Epoch 134/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0905 - coeff_determination: -0.1502 - lr: 7.8125e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3032 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.07982\n",
      "Epoch 135/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0918 - coeff_determination: -0.0847 - lr: 7.8125e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3036 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.07982\n",
      "Epoch 136/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1016 - coeff_determination: -0.1880 - lr: 7.8125e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3039 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.07982\n",
      "Epoch 137/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1152 - coeff_determination: -0.4303 - lr: 7.8125e-08 - val_loss: 0.0974 - val_coeff_determination: -0.3042 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.07982\n",
      "Epoch 138/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0998 - coeff_determination: -0.1802 - lr: 7.8125e-08 - val_loss: 0.0974 - val_coeff_determination: -0.3044 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.07982\n",
      "Epoch 139/150\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.1051 - coeff_determination: -0.1756 - lr: 7.8125e-08 - val_loss: 0.0974 - val_coeff_determination: -0.3041 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.07982\n",
      "Epoch 140/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0986 - coeff_determination: -0.2169 - lr: 7.8125e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3036 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.07982\n",
      "Epoch 141/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1000 - coeff_determination: -0.1875 - lr: 7.8125e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3039 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.07982\n",
      "Epoch 142/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1003 - coeff_determination: -0.1585 - lr: 7.8125e-08 - val_loss: 0.0974 - val_coeff_determination: -0.3042 - val_lr: 7.8125e-08\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.07982\n",
      "Epoch 143/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1146 - coeff_determination: -0.3576 - lr: 3.9062e-08 - val_loss: 0.0974 - val_coeff_determination: -0.3042 - val_lr: 3.9062e-08\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.07982\n",
      "Epoch 144/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0983 - coeff_determination: -0.1165 - lr: 3.9062e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3039 - val_lr: 3.9062e-08\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.07982\n",
      "Epoch 145/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0984 - coeff_determination: -0.2144 - lr: 3.9062e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3037 - val_lr: 3.9062e-08\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.07982\n",
      "Epoch 146/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1079 - coeff_determination: -0.2551 - lr: 3.9062e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3038 - val_lr: 3.9062e-08\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.07982\n",
      "Epoch 147/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1011 - coeff_determination: -0.1467 - lr: 3.9062e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3038 - val_lr: 3.9062e-08\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.07982\n",
      "Epoch 148/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1070 - coeff_determination: -0.2070 - lr: 3.9062e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3037 - val_lr: 3.9062e-08\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.07982\n",
      "Epoch 149/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0874 - coeff_determination: -0.0149 - lr: 3.9062e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3036 - val_lr: 3.9062e-08\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.07982\n",
      "Epoch 150/150\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.1020 - coeff_determination: -0.1894 - lr: 3.9062e-08 - val_loss: 0.0973 - val_coeff_determination: -0.3028 - val_lr: 3.9062e-08\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.07982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ada73ef98>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=32, validation_data=[X_test, y_test], callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Solvent</th>\n",
       "      <th>Quantum Yield</th>\n",
       "      <th>Solvent.1</th>\n",
       "      <th>File</th>\n",
       "      <th>File.1</th>\n",
       "      <th>Absorption</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Benzene</td>\n",
       "      <td>210</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>0.053</td>\n",
       "      <td>hexane</td>\n",
       "      <td>A01_71-43-2_Benzene.abs.txt</td>\n",
       "      <td>A01_71-43-2_Benzene.ems.txt</td>\n",
       "      <td>254.75</td>\n",
       "      <td>C1=CC=CC=C1</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Toluene</td>\n",
       "      <td>2860</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>0.170</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>A02_108-88-3_Toluene.abs.txt</td>\n",
       "      <td>A02_108-88-3_Toluene.ems.txt</td>\n",
       "      <td>261.75</td>\n",
       "      <td>CC1=CC=CC=C1</td>\n",
       "      <td>289.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>o-Xylene</td>\n",
       "      <td>254</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>0.170</td>\n",
       "      <td>hexane</td>\n",
       "      <td>A03_95-47-6_o-Xylene.abs.txt</td>\n",
       "      <td>A03_95-47-6_o-Xylene.ems.txt</td>\n",
       "      <td>263.00</td>\n",
       "      <td>CC1=CC=CC=C1C</td>\n",
       "      <td>291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>m-Xylene</td>\n",
       "      <td>284</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>0.130</td>\n",
       "      <td>hexane</td>\n",
       "      <td>A04_108-38-3_m-Xylene.abs.txt</td>\n",
       "      <td>A04_108-38-3_m-Xylene.ems.txt</td>\n",
       "      <td>265.00</td>\n",
       "      <td>CC1=CC(=CC=C1)C</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>p-Xylene</td>\n",
       "      <td>770</td>\n",
       "      <td>cyclohexane</td>\n",
       "      <td>0.220</td>\n",
       "      <td>hexane</td>\n",
       "      <td>A05_106-42-3_p-Xylene.abs.txt</td>\n",
       "      <td>A05_106-42-3_p-Xylene.ems.txt</td>\n",
       "      <td>275.00</td>\n",
       "      <td>CC1=CC=C(C=C1)C</td>\n",
       "      <td>291.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #      Name  Epsilon      Solvent  Quantum Yield    Solvent.1  \\\n",
       "0  1   Benzene      210  cyclohexane          0.053       hexane   \n",
       "1  2   Toluene     2860  cyclohexane          0.170  cyclohexane   \n",
       "2  3  o-Xylene      254  cyclohexane          0.170       hexane   \n",
       "3  4  m-Xylene      284  cyclohexane          0.130       hexane   \n",
       "4  5  p-Xylene      770  cyclohexane          0.220       hexane   \n",
       "\n",
       "                            File                         File.1  Absorption  \\\n",
       "0    A01_71-43-2_Benzene.abs.txt    A01_71-43-2_Benzene.ems.txt      254.75   \n",
       "1   A02_108-88-3_Toluene.abs.txt   A02_108-88-3_Toluene.ems.txt      261.75   \n",
       "2   A03_95-47-6_o-Xylene.abs.txt   A03_95-47-6_o-Xylene.ems.txt      263.00   \n",
       "3  A04_108-38-3_m-Xylene.abs.txt  A04_108-38-3_m-Xylene.ems.txt      265.00   \n",
       "4  A05_106-42-3_p-Xylene.abs.txt  A05_106-42-3_p-Xylene.ems.txt      275.00   \n",
       "\n",
       "            SMILES  Emission  \n",
       "0      C1=CC=CC=C1     287.0  \n",
       "1     CC1=CC=CC=C1     289.5  \n",
       "2    CC1=CC=CC=C1C     291.0  \n",
       "3  CC1=CC(=CC=C1)C     290.0  \n",
       "4  CC1=CC=C(C=C1)C     291.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0                cyclohexane\n",
       "1                cyclohexane\n",
       "2                cyclohexane\n",
       "3                cyclohexane\n",
       "4                cyclohexane\n",
       "5                cyclohexane\n",
       "6                cyclohexane\n",
       "7                cyclohexane\n",
       "8                cyclohexane\n",
       "9                cyclohexane\n",
       "10               cyclohexane\n",
       "11               cyclohexane\n",
       "12               cyclohexane\n",
       "13                  methanol\n",
       "14                   ethanol\n",
       "15               cyclohexane\n",
       "16               cyclohexane\n",
       "17                       PBS\n",
       "18               cyclohexane\n",
       "19               cyclohexane\n",
       "20                   ethanol\n",
       "21               cyclohexane\n",
       "22               cyclohexane\n",
       "23                chloroform\n",
       "24                   ethanol\n",
       "25               cyclohexane\n",
       "26               cyclohexane\n",
       "27                   ethanol\n",
       "28                   ethanol\n",
       "29                  methanol\n",
       "               ...          \n",
       "261                  toluene\n",
       "262                  toluene\n",
       "263                  toluene\n",
       "264                  toluene\n",
       "265                  toluene\n",
       "266                  toluene\n",
       "267                  toluene\n",
       "268                  benzene\n",
       "269                  toluene\n",
       "270               chloroform\n",
       "271              acetic acid\n",
       "272        dimethylformamide\n",
       "273          dichloromethane\n",
       "274          dichloromethane\n",
       "275          dichloromethane\n",
       "276               chloroform\n",
       "277                  ethanol\n",
       "278    borate buffer (pH 10)\n",
       "279        chloronaphthalene\n",
       "280                 pyridine\n",
       "281                 pyridine\n",
       "282            chlorobenzene\n",
       "283            diethyl ether\n",
       "284            diethyl ether\n",
       "285                  ethanol\n",
       "286          dichloromethane\n",
       "287          dichloromethane\n",
       "288                  ethanol\n",
       "289                  toluene\n",
       "290                  toluene\n",
       "Name: Solvent, Length: 291, dtype: object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['Solvent'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "print(len(tmp['Name']))\n",
    "print(len(set(tmp['Name'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x274281ce160>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXGwXFd93z8/PS32ExA/gZUOfrIqM3FEbBxb+NWYeqaDDYlMqG2NMdgOmTQtHU1nQlMIVUeedLBN07ESNQNk6tK4DE2gLWAMVQS4FUzsTDueQvyUZwEyVqLagPVEY4Va7gQLeJJ+/WPvyqt99+6e3b17955zv58ZjXbvnrd7zrn3/u7v/M73/I65O0IIIdJizbQrIIQQonxk3IUQIkFk3IUQIkFk3IUQIkFk3IUQIkFk3IUQIkFk3IUQIkFk3IUQIkFk3IUQIkHWTuuHL7zwQt+8efO0fl4IIaLkwIEDf+3uGwaVm5px37x5M4uLi9P6eSGEiBIz+25IOYVlhBAiQWTchRAiQWTchRAiQWTchRAiQWTchRAiQWTchRAiQWTchRAiQQYadzP7hJk9Z2bfKvjczOz3zeyImX3DzN5QfjWFEEIMQ8gipj8E/i3wyYLP3wZcmv17I/Cx7P9GsndpmT37D3PsxEkumptl57YtbN86n8zvTbMedWmrEDEw0Li7+/8ws819itwCfNLbO21/zczmzOw17v79kuoYDXuXlrnrC9/k5MppAJZPnOSuL3wTYCJGqOrfm2Y96tJWIWKhjJj7PPBs1/uj2bHGsWf/4bPGp8PJldPs2X84id+bZj3q0lYhYqEM4245xzy3oNkOM1s0s8Xjx4+X8NP14tiJk0Mdj+33plmPurRViFgow7gfBS7uer8ROJZX0N0fcPcFd1/YsGFgUrPouGhudqjjsf3eNOtRl7YKEQtlGPd9wK9mqplrgReaGG8H2LltC7OtmXOOzbZm2LltSxK/N8161KWtQsTCwAlVM/s08GbgQjM7CtwNtADc/d8DDwO/BBwBXgT+4aQqW3c6E3tVKToG/V5V6pIq2j3Ob+xdWuaefYc4cXIFgPXrWtx90+WaiBVJY22RS/UsLCy48rlPjl51CbQ93ftuvaJRRm3v0jI7P3eQlTPnXuetGWPPbVc2qi9EGpjZAXdfGFROK1QTReqSNnv2H15l2AFWTnvj+kI0Cxn3RJG6pE2/9jatL0SzmNo2e2KyXDQ3y3KO8WqauqSoHzqfgVa+ijSR554ow6hL9i4tc93uR7hk15e5bvcj7F1arqqaE2fnti201qxeitGaMXZu23J2bmL5xEmcl1a+ptQHopnIuCfK9q3z3HfrFczPzWLA/Nxs7mRq6sZt+9Z59rzzSuZmW2ePrV/XOjuZqrkJkSoKywxBnYfvRXUbVL9+xq0ubRuXfv2guQmRKjLugdQ5cdU4dWu6cdPchEgVhWUCqfPwfZy6NX1Zv1a+ilSRcQ+kzh7uOHVrunELnZsQIjYUlgmkDsP3orj6OHWrOmVCHQmZmxAiNmTcA9m5bUvucv6qPNx+cfVx6ybjJkR6yLgHMm0Pt19c/bFdN0y1bmI1dVZWiWYg4z4E0/RwB8XV5X3Xhzorq0RzkHGvgFG9uO6/W2PG6ZwMnk1RtcREE9YOiPoj4z5hRvXiev8uz7A3SdUSE3VWVonmICnkhBlVg573dwAzZpLs1Zymrx0Q9UCe+4QZ1Ysr+vyMO8/sfvvY9RKTY9rKKiFAnvvEGdWLk/cXL1oYJeqAPPcJM6oXJ+8vbqReEtNGxn3CjKqPn7auPmakMRdCG2SLxNDG4CJ1tEG2aCR1zt4pRJXIuIukkMZciDYy7iIppDISoo2Mu0iKpuenF6KD1DIiKaQyEqKNjLtIDmnMhZBxFxUTowY9xjoLIeMuKiPGPOcx1lkI0ISqqJAYNegx1lkICPTczexG4KPADPBxd9/d8/km4I+AuazMLnd/uOS6igjpDmkUrYWuswZdunkRKwM9dzObAe4H3gZcBtxpZpf1FPuXwIPuvhW4A/h3ZVdUxEcnpLHcx7BDvTXo0s2LWAkJy1wDHHH3p939J8BngFt6yjjwU9nrC4Bj5VVRxErRhiPd1F2DLt28iJWQsMw88GzX+6PAG3vK3AN8xcz+KfBy4K15X2RmO4AdAJs2bRq2riIy+oUuDKJQnkg3L2IlxLhbzrHeUfadwB+6+++Z2ZuAT5nZ6939zDl/5P4A8AC0s0KOUmERDxfNzbKcY+Dn52Z5bNcNuX9TR9mhdPMiRkLCMkeBi7veb2R12OU9wIMA7v6/gPOBC8uooIiXYUMavTH6juxw79JyBbUVIi1CjPvjwKVmdomZvYz2hOm+njLfA94CYGY/R9u4Hy+zoiI+ht1uTrJDIcpjYFjG3U+Z2XuB/bRljp9w90Nm9iFg0d33AR8A/oOZvZ92yObXfFq7gIhaMUxIQ7JDIcojSOeeadYf7jn2wa7XTwLXlVs10TSKYvSSHQoxPFqhKmqDZIdClIdyy4jaINmhEOUh4y5qhWSHQpSDwjJCCJEgMu5CCJEgMu5CCJEgMu5CCJEgMu5CCJEgMu5CCJEgMu5CCJEgMu5CCJEgWsQkRB+688tfMNvCDE68uHJ29SysXlGbd0wLs0TV2LSSNy4sLPji4uJUfluIEDr55Yu2CmzNGDisnPG+x2ZbM31THQsxDGZ2wN0XBpVTWEaIAgbtAbty2s8x4kXHlJNeTAOFZcTEqOOWecNQZh555aQXVSPPXUyEFLbMKzOPvHLSi6qRcRcToa5b5u1dWua63Y9wya4vc93uR/o+bPLyy3fTmjFaa2zgMeWkF9NAYRkxEeq4ZV7vBGlnNAHkhot688tLLSNiQsZdTIRht8yrIj7fbzRR9Fsh+eX7PRiEmBYKy4iJMMyWeVXF5+s4mhBiUshzbxBVqleG2TJvFI86j0Hta8IG3LErlER5yLg3hGHjzWUQumVeGR51SPt2btuyalFSSpOd0zjHor4oLNMQ6qpegWLPeRiPOqR927fOc9+tVzA/N4sB83OzSa0crfM5FtUjz70h1DneXIZHHdq+lDfgrvM5FtUj494QJhFvLiu+O0x8vogmxNP7sXdpmTVmnM7JFdWUPhDnIuPeEMqON5cd3x3Xo049nt6PzrnIM+xN6QOxGsXcG0LZ8ea6xXdTj6f3oyjB2YxZY/pArEaee4MoM95cx/huyvH0fhT1+Rn3RvaHaCPPXYxEGQoXUQ46FyKPIONuZjea2WEzO2JmuwrKvMvMnjSzQ2b2X8qtpqgbw6xAFZNF50LkMTAsY2YzwP3ALwBHgcfNbJ+7P9lV5lLgLuA6d3/ezH56UhUW9aAMhYsoh7qcC62OrRcDt9kzszcB97j7tuz9XQDufl9Xmd8F/sLdPx76w9pmT4h0yNuSUNsLToYyt9mbB57ten80O9bNzwI/a2aPmdnXzOzG8KqKOjFMvnMhOtRNPSXC1DKWc6zX3V8LXAq8GdgI/E8ze727nzjni8x2ADsANm3aNHRlxWRRbhIxKnVUTzWdEM/9KHBx1/uNwLGcMn/s7ivu/gxwmLaxPwd3f8DdF9x9YcOGDaPWWUyIGL0vjTTqgRQ79SPEuD8OXGpml5jZy4A7gH09ZfYC1wOY2YW0wzRPl1lRMXli875S2Kc1FaTYqR8Djbu7nwLeC+wHvg086O6HzOxDZnZzVmw/8AMzexJ4FNjp7j+YVKXFZIjN+4pxpJEqTV4hXFeCVqi6+8PAwz3HPtj12oHfzP6JSIktP0tsI43UaeoK4bqiFariLLF5X7GNNISoEuWWEecQk/cV20hDiCqRcRcDqevKw7qszBSijsi4BzBp41ZX4wn1176XPdKo07moU11EfCjmPoBJy+3qLudrkiKlTueiTnURcSLjPoBJG7e6G8+yFSl1XnRUp3NRp7qIOJFxH8Ck5XZ1l/OVqUipuzdap3NRp7qIOJFxH8Ck5XZ1l/OVufKw7t5onc5Fneoi4kTGfQCTXlZd92XbZWrf6+6N1ulc1KkuIk6klhnApOV2Mcj5ylKkXDQ3y3KOIa+LN1qnc1Gnuog4GbhZx6TQZh3NQxs6CDE+oZt1yHMXhZSts5Y3KkR1yLiLXCa1eCmm9AZCxIyMu8iln7JFxnk8mrbytGntrQsy7iKXuitbYqXu6RzKpmntrROSQopcpLOeDHXX+ncoayVxLO1NERl3kYt01pMhhhFRmSuJY2hvqsi4i1yq2rijzrlmJkEMI6Iyve0Y2psqirmLQiatbGliPDaGDUbK9LZjaG+qyHMXU6OJ8dgYtjIs09uOob2pIs9dTI2mxmPrrvUv29uue3tTJTnjLk1tPNQ910xT0UriNEjKuDcxhhszisfWF3nb8ZNUzL2JMdyYUTxWiMmRlOfe1BhuzMhDFGIyJGXcq47hKr4vqkDXmRiFpMIyVa6qrPt+oCINdJ2JUUnKc69ylr+MrIlle2Ty8NJD2TnFqCRl3KG6GO648f2ylT1SCqXJpOaR5AikT1JhmSoZdxVf2coeKYXSZBK5WRTqaQZBxt3MbjSzw2Z2xMx29Sl3m5m5mQ3c3y92xo3vl+2RSSmUJmXOI3WStL3vs0/IEWgAA427mc0A9wNvAy4D7jSzy3LKvRL4DeDrZVeyjoyr0S7bI1P2vTQpay1At7dehByBtAiJuV8DHHH3pwHM7DPALcCTPeX+FfC7wD8vtYY1Zpz4ftmrM7XaczpUEbsuYx4pL2zXixyBtAgJy8wDz3a9P5odO4uZbQUudvcv9fsiM9thZotmtnj8+PGhK5sSZa/O1GrP6okpdj3IK5cjkB4hnrvlHPOzH5qtAT4M/NqgL3L3B4AHABYWFnxA8eQpW9mj1Z7VEpNMsWiBH7QdAall0iPEcz8KXNz1fiNwrOv9K4HXA39qZt8BrgX2NWFSVTSbmCaxiyZmP3L7VTy26wYZ9gQJMe6PA5ea2SVm9jLgDmBf50N3f8HdL3T3ze6+GfgacLO7L06kxkLUhJgmsRW2ax4DwzLufsrM3gvsB2aAT7j7ITP7ELDo7vv6f4MQaRLbJLbCds0iaIWquz8MPNxz7IMFZd88frVEEVpZ2J8q+0ebWog6k1z6gZRRioH+TKN/5A2LuqL0AxGhFAP9Uf+MT2cV6yW7vsx1ux+ppaxThCHPPSJiUmdMA/XPeGhkmBby3CMiJnVG2YR4lE3unzLQyCctZNwjosrNSOpE6ErQpvZPWWjkkxYKy9SQIsVHU9UZoStBm9o/ZVH1NpVissi414xBcc8mqjOG8Sib2D9lEZtuX/RHxn3KdHvpc+tanHhxhd6kO3XNV1IV8ignQ94I8b5br9DIJxFk3KdIr5f+/IsrhWWbHPeUR1k+RSPE+269gsd23TDl2okykHGfIiE5tjs02UtVLL18iuYx7tl3SP2cCDLuUyTUG5eXqlh62RRdeydOrnDiZHsEKZ173CRn3GPKvdIvx3aHGTNl7xuSmK6BaRFy7UHbm//AgwcBGfjYSErnHtPOOJCvy+5mtjXD773rSt1UQxDbNTAtBl173Zx2Vx9GSFLGvewVdpPOs9GbY3v9uhbrWi+dkvPWJnV6KkGrLMPIy+++fl2rsLz6MD6SCsuUucKuqjwb3bHkzm92OHFyRTHPIdEqy3B65zH2Li2z86GDrJzO3wFTfRgXSbmGZeYWmYYHKK9zfJRfZkz67GysPoyLpIx7mblFhvEAywrfyOscn9Tyy1SZgnfP/sOsnMm37jH3YVNJKixTph46dFVkmeEbrcQcn5Q08VWn4O3nREixFR9Jee5lEuoBlhlKSc3rnBbbt87z2K4beGb323ls1w3RGqWqw3RFTsT83Gy0fdhkkjLuZcrgQneLLzOUoh3qRTdVh+nkXKRFUmGZ0NSwoYSsiiw7lKKVmKJD1WG6lEJaIjHjPo0JSSW1EpNiGteWnIt0SMq4D+vplLFMXd7OcCg1QDi6tsQ4mHsfYesEWVhY8MXFxVK/s1ddAG1PJy9uPUxZUQ7qcyHGx8wOuPvCoHJJTahu3zrPO66eZ8YMaCfdesfV+cPMovj8Bx48WImmuIlokZYQ1ZGUcd+7tMznDyxzOhuNnHbn8weWc410URz+tLsSTk0ILdISojqSMe57l5b5wIMHg73xEMWBvMpyUWoAIaojCePeieWeLpg/yPPGQ1OeyqssD+mohaiOJNQyw2xX1/HGO/tE7tl/uO+mBbF7lXVSp0xL/VGnPhiFqusfe3+JNkHG3cxuBD4KzAAfd/fdPZ//JvCPgVPAceAfuft3S65rIcN6153ynQu2V8HRIXavsurcJCFUraOuYx8MQ9X1j72/xEsMDMuY2QxwP/A24DLgTjO7rKfYErDg7j8PPAT8btkV7cew3nV3+SKvP4Xt7ZqgThmUNXHUPqgyG2M/qj6HTbhm+lGX814GITH3a4Aj7v60u/8E+AxwS3cBd3/U3V/M3n4N2FhuNftTFMv9lWs3DYzxFnn9Z9yjNuxAYbgpZO/MGAjJJTSKQqdOW/VVrTBqsqKpTue9DEKM+zzwbNf7o9mxIt4D/LdxKjUsRQm3fnv7FQN174MUHDE/yTvtDj0eGyFe5igKnTp5r1UrjJqsaKrTeS+DEOOeZwlyZSlm9ivAArCn4PMdZrZoZovHjx8Pr2UAeWleQ3Tv/RQcsT/J+6mHUiDEyxxFoVMn77VqhVGTFU11Ou9lEGLcjwIXd73fCBzrLWRmbwV+C7jZ3X+c90Xu/oC7L7j7woYNG0ap71CEPInzvP53XD3Pnv2Hed9nn6jsST6JEcJ8n/zcKRDiZY6SRrlO3mvVaaCbnHa6Tue9DELUMo8Dl5rZJcAycAfwy90FzGwr8AfAje7+XOm1HJHQJ3HeJtX9pJVlP8knpVBIPWNlaPuGVejUrd+qVhg1NTNk3c77uAw07u5+yszeC+ynLYX8hLsfMrMPAYvuvo92GOYVwOesHc/9nrvfPMF6n8PepWXu2XeIEydXAFi/rsXdN13eN0tkkZY3RDNf9pO87Dz0HVLPKjip9qXebyKf1M579Fkh9y4ts/NzB1dt7NuaMW7/Oxfz+QPLq57E77h6vvD4f/ra9/r+3iSyGF6y68u5kxgGPLP77aX9jhAifhqTFbJox/aV086jTx3PjR8++tTxXE/5Pw8w7ADnt8rvstBYX8zKHVFfdF2lSfTpB/rFv4+dOJkbP3z/Z5/ILR8yhnn+xZXSV+yFxPq0crC+xLxcX9dVukTvufeLf09q9rtsxUyIQiE1DW4qxC6X1XWVLtF77ju3bSmMuRfNcud5ykaY596hbMXMIIVCahrcVJjUZHhVFF0/qaxibjLRe+7bt86z551XMjfbOnts/boWe267svDmyvOU333tptzVWkVUrX1NTYObCrE/dIuuH4NoRh8in+g99w4vP28tL5xcWRXzLIqHFnnKg9QyUI72ddg4bawa3Jjj0SEMuyn7sEy6/3Zu28L7P/vEqlGrQzSjD5FP9Ma934QQMNRk0W9vv6KvcTcY+QbrvkkvmG3xw5+cYuW0B9Wr+3hMhrIJk3XXv25D7jVz/evGX4FdRf9t3zrP+woEBrGMPkQ+0Rv3QRNCw8ZD5ws8sfm52bMbfPQjz9OCcx8yncVWw9QL4ls5GHs8OoRHn8rPkVR0fBjK6r9B3n/RNa+QX9xEb9xHiXn2+2yc8EeRp3Xe2jVBO0Wl5inFHo8OYZJtHPa7QxyLPO8/1pCf6E/0xr0o5um0U9vmZUDs55GME/4o8rRCtwBMzVOadDx6GvQa0AtmW7kjsTLaOEz/7V1aZudDB88J9RWFW7pHtt2hwvNbazjx4up5KxEn0Rv3PK+jQ55hD/FIRg1/jOOtpegppeYR5o3MWjNGa42dI8Utq43D9N+9Xzx01rCH0PHgu0OFs60ZPnz7VTLqiRC9ce/2tIu0uTNmnHGfuEdS5GnBah19a43xivPXJu0pxTgJ3I+8kdnKaWf9uhbrXra29DYW9R/AdbsfOefY8y+uHj30Y8Ys+fmQphN94rBupp2Aa1C64I6Bn4/cyDWVaV9fkH+NzbZmgkN/g8orWV39CU0cFr3nDi/FQYseU1XFeAeNIjqGPUR1I+pHHeYQiuZ1QldYdxyLomu0qrakvv6hDkS/QrU7t0ceVcd4O9v9Fa12TUkp0jTqsAVd0fXjtEN9Rcy2ZvjI7Ved3YJymm2JPR9PLETvuffbXGMa4Y+yRhHybKZDv36vwxxC0eih2yM/duIkc+tauJO7aruKtvTrxyasf6gD0Rv3OnnCg2Lu4+rlIZ2VnXUkpN+nvZCsn4JmUN3yDO4kQoSD+rEJ6x/qQPRhmX6ecNXDvUGjiNAdnJSGdTrE0O+jbmBdZShkUD8qCV41RO+5FyU+6lDlcK/I8zAYykPql4Z179KyvPcRGRTqKpq3qVv621FGD1WGQgZ55qmtf6gr0Xvu27fOD1QJVDXcK8sj6VdeE0+jEeK5zlj+hGTR8aoZZzu8KkMhg+6DUUcfYjiiNu6di30QVQ33ylIg5H1Ph7qFCWIhJOSSt6K53/EqGTesUmUoJOQ+6KjKntn99rMKHlEu0Rr3QRLIDkb7Rqhi49+yPJLO9xSR6sTTJDdqDvFc5wsMXef4NDeSHnc+oErpYxM98zpuMh5tzL3f5GUnYVj3wo6qFCdlqSm2b52f+kKTSTFq9sJxCFmA1C8WvHdp+ZztHJdPnGTn5w72rV8ZctbOdxQ5MaEP+nGkj6O0Y9qqoiqpq7ot2vQDg5aCX7f7kbHysocwaS160VLzmL2gojadt3ZNbnbFss5XaF8WndOr7v1Kbv3mZls8cfcvjvx7eX/XrVX/mx+dWrU/cDeTyGvTb2OZ0HY0iSpsTTfJpx8Y5IlNegIp9Gk9zgOgDotmxiGv7cOmRe6E1MZtf2hfFnmceYa93/FR1Cm919SgZGCtGeNvfnTqbLnOaOLeLx4aOSFdbx1G3Vim9ztjvYZDGMbWVNkX0Rr3QXKqSecBCbl5yxiuxTq8LWr7MAmuOnTO47jD3Sr7chTnol+osZf5uVl++ONTq4zvyhk/x9gP21+hdQh1kuoasiiTUFtTdV9ENaHaPWmxZ/9h3nH1fOGkzc5tW2jNnCtha81YaRNIITfvuJNgdZykCaWo7UWywvXrWn1zo3R/xzTUQuvXtYY6Poo6JdRgdob7LxSMGroZtr9C6xDqJMWwMGxcQierq+6LaIx7nhTs8weW2bltS7GcKm9L95IIuXnHCQ1NM7lSGQ+Vojaeds+9Ee6+6XJecX7YQHIaaqG7b7o811m4+6bLc8uPok4JMZi9o9MQhumvYesw6m+npPgKVQdV3RfRGPdhnnp7l5b5wIMHV01ErZzx0p6SITfvONriaXk8ZT1UitrYufDzboQTgRtOTEMttH3rPHtuu/Kceu+57crC4fQocsC8a6o1Y8zNtnK/4/rXbQiq+zD9lVuHNcb6dfl1GPW3Y1d89RKi26+6L6KJuYc+9TrGqWjhSVlLyUMm6MZZZj3uU37UiZuih8pdX/jGUN83SoKrfjtZ9X7HNBg2Zj9KeQifQH/0qeMDv3PY/ip7Er9oG8wf/vhU41JpVJ12Ici4m9mNwEeBGeDj7r675/PzgE8CVwM/AG539++UWdHQSYt79h3qOyEUENY9yyADOejm7d28o7O1Wcf77ve340wIjzNxU/TwOLlyZqiJzWG2iOueJ+m9+JuwHWE3eddU0XXY70FvMHJ/lTnx3Pmee7946Bz1z4mTK4XrBFJV11Stfhto3M1sBrgf+AXgKPC4me1z9ye7ir0HeN7df8bM7gB+B7i9zIqGPPX2Li0XStM6nHGCPIayZrY7ZYf9rnGe8uMkiQrxnkO/r9dIDOrT2KWfk6Bfn/XL7V6n3b62b53nnn2HVh1fOePcs+/QUNdI7FSp2AqJuV8DHHH3p939J8BngFt6ytwC/FH2+iHgLWblZlsKiWGGxqNDypUZ8x7lu8ZZwj1OSGeYIeKwE0Eh/aCcI+fSr8/qsDNUKKHrBJqgrqmKkLDMPPBs1/ujwBuLyrj7KTN7AXg18NfdhcxsB7ADYNOmTUNXdtBTL9TYhJQrc2Z71O8a9Sk/Tkhn+9b5VUPofr8zDE1QTpRNvz5LcaSja6Q8Qjz3PA+8d7YypAzu/oC7L7j7woYNYTP9wxBqbELKlTmzXfUs+bge3d03XV6YlbKDMZyXD81RTpRJSPrcGEY6oesEdI2UR4hxPwpc3PV+I3CsqIyZrQUuAP5vGRUchn6pcjuEGrkyh7xVD5/HzcrX/few+sltwLuv3TS0IYkpjFAXUumz0HUCqbS3DgxMHJYZ678A3gIsA48Dv+zuh7rK/Dpwhbv/k2xC9VZ3f1e/7x03cVgRvTPt179uA48+dXykYWuZs/YxKwDUD9MllT4LbUcq7Z0UoYnDgrJCmtkvAR+hLYX8hLv/azP7ELDo7vvM7HzgU8BW2h77He7+dL/vnJRxF0KIlCk1K6S7Pww83HPsg12vfwS8c9hKCiGEmAzRpB8QQggRjoy7EEIkiIy7EEIkiIy7EEIkiIy7EEIkiIy7EEIkiIy7EEIkSNAipon8sNlx4LsV/dyF9CQxS4RU2wVqW6yobZPnb7v7wORcUzPuVWJmiyErumIj1XaB2hYralt9UFhGCCESRMZdCCESpCnG/YFpV2BCpNouUNtiRW2rCY2IuQshRNNoiucuhBCNInrjbmbnm9mfmdlBMztkZvdmxy8xs6+b2V+a2WfN7GXZ8fOy90eyzzdPs/4hmNmMmS2Z2Zey90m0zcy+Y2bfNLMnzGwxO/YqM/tq1ravmtn67LiZ2e9nbfuGmb1hurXvj5nNmdlDZvaUmX3bzN4Ue9vMbEt2rjr//p+ZvS/2dnUws/dnNuRbZvbpzLZEe69Fb9yBHwM3uPuVwFXAjWZ2LfA7wIfd/VLgeeA9Wfn3AM+7+88AH87K1Z1/Bny7631Kbbve3a/qkpjtAv4ka9ufZO8B3gZcmv3bAXys8poOx0eB/+7urwOupH3+om6bux/OztVVwNXAi8B/JfJ2AZjZPPAbwIK7v572xkR3EPO95u7J/APWAX8OvJH2YoO12fE3Afuz1/uBN2Wv12blbNqcnKE5AAAC00lEQVR179OmjbRvmBuAL9HewjSVtn0HuLDn2GHgNdnr1wCHs9d/ANyZV65u/4CfAp7p7fsU2tZVx18EHkulXcA88Czwquze+RKwLeZ7LQXPvRO2eAJ4Dvgq8L+BE+5+KitylPbJg5dOItnnLwCvrrbGQ/ER4F8AZ7L3ryadtjnwFTM7YGY7smN/y92/D5D9/9PZ8bNty+hud914LXAc+I9ZOO3jZvZy0mhbhzuAT2evo2+Xuy8D/wb4HvB92vfOASK+15Iw7u5+2ttDxY3ANcDP5RXL/rc+n9UKM/v7wHPufqD7cE7R6NqWcZ27v4H28P3Xzezv9SkbU9vWAm8APubuW4Ef8lKoIo+Y2kYWd74Z+NygojnHatmubJ7gFuAS4CLg5bSvy16iudeSMO4d3P0E8KfAtcCcmXX2iN0IHMteHwUuBsg+v4D2pt515DrgZjP7DvAZ2qGZj5BG23D3Y9n/z9GO3V4D/JWZvQYg+/+5rPjZtmV0t7tuHAWOuvvXs/cP0Tb2KbQN2kbvz939r7L3KbTrrcAz7n7c3VeALwB/l4jvteiNu5ltMLO57PUs7ZP0beBR4Las2D8A/jh7vS97T/b5I54FzuqGu9/l7hvdfTPtYfAj7v5uEmibmb3czF7ZeU07hvstzm1Db9t+NVNgXAu80AkF1A13/z/As2a2JTv0FuBJEmhbxp28FJKBNNr1PeBaM1tnZsZL5yzee23aQf8SJkJ+HlgCvkHbOHwwO/5a4M+AI7SHj+dlx8/P3h/JPn/ttNsQ2M43A19KpW1ZGw5m/w4Bv5UdfzXtCeS/zP5/VXbcgPtpz6d8k7aqYert6NO+q4DF7LrcC6xPoW20RQs/AC7oOhZ9u7L63gs8ldmRTwHnxXyvaYWqEEIkSPRhGSGEEKuRcRdCiASRcRdCiASRcRdCiASRcRdCiASRcRdCiASRcRdCiASRcRdCiAT5/6E1KFfWc1NDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(tmp['Emission'], tmp['Quantum Yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethanol                           45\n",
       "cyclohexane                       29\n",
       "methanol                          14\n",
       "hexane                            11\n",
       "toluene                           10\n",
       "benzene                            9\n",
       "water                              8\n",
       "acetonitrile                       6\n",
       "chloroform                         5\n",
       "dichloromethane                    5\n",
       "ethanol (basic)                    3\n",
       "dimethylformamide                  3\n",
       "dioxane                            3\n",
       "chloronaphthalene                  2\n",
       "phosphate buffer (pH 7, 0.1 M)     2\n",
       "diethyl ether                      2\n",
       "tetrahydrofuran                    2\n",
       "glycerol                           2\n",
       "PBS                                2\n",
       "water (pH 4)                       1\n",
       "pyridine                           1\n",
       "water (pH 10)                      1\n",
       "3-methylpentane                    1\n",
       "propanol                           1\n",
       "water (pH 5 to 9 )                 1\n",
       "30% tris buffered (in DMSO)        1\n",
       "DMSO                               1\n",
       "H2SO4 aq (1 N)                     1\n",
       "ethanol                            1\n",
       "Name: Solvent.1, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['Solvent.1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16.,  4.,  3.,  5.,  3.,  4.,  1.,  4.,  2.,  3.]),\n",
       " array([0.0016 , 0.09644, 0.19128, 0.28612, 0.38096, 0.4758 , 0.57064,\n",
       "        0.66548, 0.76032, 0.85516, 0.95   ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tmp.loc[tmp['Solvent.1']=='ethanol','Quantum Yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4., 5., 7., 2., 2., 0., 1., 0., 2., 6.]),\n",
       " array([0.0042 , 0.10378, 0.20336, 0.30294, 0.40252, 0.5021 , 0.60168,\n",
       "        0.70126, 0.80084, 0.90042, 1.     ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADL5JREFUeJzt3W+sZPVdx/H3p7tgRamY7q1pCtcrSUskJC3khrQhqRZqQ8HAE2IgQa0h3rTGhkYTs02f+OcJNbH+SYi6UWzVlrZiqYRtq2gh2KZQd2FL+WsornYFu5BaWtpYSv36YAayLvfunGXnzPBl36/khpk7Z2e+v71335w9c87dVBWSpD5etuwBJElHx3BLUjOGW5KaMdyS1IzhlqRmDLckNWO4JakZwy1JzRhuSWpm+xhPumPHjlpbWxvjqSXpJWnv3r1PVNXKkG1HCffa2hp79uwZ46kl6SUpyb8P3dZDJZLUjOGWpGYMtyQ1Y7glqRnDLUnNzAx3kjOS7Dvk45tJ3rOI4SRJzzfzdMCqegh4A0CSbcB/AjeOPJckaQtHe6jkAuArVTX4fENJ0nwdbbgvB64fYxBJ0jCDr5xMciJwCfDeLR7fADYAVldX5zLc8WJt5+6lvO7+ay5eyutKOjZHs8f9duCuqvraZg9W1a6qWq+q9ZWVQZfbS5JegKMJ9xV4mESSlm5QuJOcBPwM8Ilxx5EkzTLoGHdVfQd45cizSJIG8MpJSWrGcEtSM4Zbkpox3JLUjOGWpGYMtyQ1Y7glqRnDLUnNGG5JasZwS1IzhluSmjHcktSM4ZakZgy3JDVjuCWpGcMtSc0YbklqxnBLUjOGW5KaMdyS1IzhlqRmBoU7ySlJbkjyYJIHkrxp7MEkSZvbPnC7PwQ+U1WXJTkROGnEmSRJRzAz3EleAbwZeAdAVT0NPD3uWJKkrQzZ4z4deBz4iySvB/YCV1fVtw/dKMkGsAGwuro67zklabC1nbuX8rr7r7l4Ia8z5Bj3duAc4I+r6mzg28DOwzeqql1VtV5V6ysrK3MeU5L0rCHhPgAcqKo7p/dvYBJySdISzAx3Vf0X8NUkZ0w/dQFw/6hTSZK2NPSskncDH56eUfII8EvjjSRJOpJB4a6qfcD6yLNIkgbwyklJasZwS1IzhluSmjHcktSM4ZakZgy3JDVjuCWpGcMtSc0YbklqxnBLUjOGW5KaMdyS1IzhlqRmDLckNWO4JakZwy1JzRhuSWrGcEtSM4Zbkpox3JLUzKB/LDjJfuBbwPeBZ6rKfzhYkpZkULin3lJVT4w2iSRpEA+VSFIzQ8NdwD8k2ZtkY8yBJElHNvRQyXlV9WiSVwG3JHmwqm4/dINp0DcAVldX5zzm+NZ27l72CJI0yKA97qp6dPrfg8CNwLmbbLOrqtaran1lZWW+U0qSnjMz3El+KMnJz94G3gbcO/ZgkqTNDTlU8mPAjUme3f4jVfWZUaeSJG1pZrir6hHg9QuYRZI0gKcDSlIzhluSmjHcktSM4ZakZgy3JDVjuCWpGcMtSc0YbklqxnBLUjOGW5KaMdyS1IzhlqRmDLckNWO4JakZwy1JzRhuSWrGcEtSM4Zbkpox3JLUjOGWpGYMtyQ1MzjcSbYluTvJzWMOJEk6sqPZ474aeGCsQSRJwwwKd5JTgYuBPxt3HEnSLNsHbvcHwG8AJ2+1QZINYANgdXX1BQ+0tnP3C/61knQ8mLnHneRngYNVtfdI21XVrqpar6r1lZWVuQ0oSfr/hhwqOQ+4JMl+4KPA+Un+etSpJElbmhnuqnpvVZ1aVWvA5cBnq+rK0SeTJG3K87glqZmhb04CUFW3AbeNMokkaRD3uCWpGcMtSc0YbklqxnBLUjOGW5KaMdyS1IzhlqRmDLckNWO4JakZwy1JzRhuSWrGcEtSM4Zbkpox3JLUjOGWpGYMtyQ1Y7glqRnDLUnNGG5JasZwS1IzM8Od5OVJvpjkS0nuS/JbixhMkrS5If/K+3eB86vqqSQnAJ9L8umqumPk2SRJm5gZ7qoq4Knp3ROmHzXmUJKkrQ06xp1kW5J9wEHglqq6c9yxJElbGRTuqvp+Vb0BOBU4N8lZh2+TZCPJniR7Hn/88XnPKUmaOqqzSqrqG8BtwIWbPLarqtaran1lZWVO40mSDjfkrJKVJKdMb/8g8FbgwbEHkyRtbshZJa8GPpRkG5PQf7yqbh53LEnSVoacVXIPcPYCZpEkDeCVk5LUjOGWpGYMtyQ1Y7glqRnDLUnNGG5JasZwS1IzhluSmjHcktSM4ZakZgy3JDVjuCWpGcMtSc0YbklqxnBLUjOGW5KaMdyS1IzhlqRmDLckNWO4JakZwy1JzcwMd5LTktya5IEk9yW5ehGDSZI2t33ANs8Av15VdyU5Gdib5Jaqun/k2SRJm5i5x11Vj1XVXdPb3wIeAF4z9mCSpM0d1THuJGvA2cCdYwwjSZptyKESAJL8MPC3wHuq6pubPL4BbACsrq7ObUCNZ23n7mWPsHD7r7l42SMcN47H769FGbTHneQEJtH+cFV9YrNtqmpXVa1X1frKyso8Z5QkHWLIWSUB/hx4oKo+MP5IkqQjGbLHfR7w88D5SfZNPy4aeS5J0hZmHuOuqs8BWcAskqQBvHJSkpox3JLUjOGWpGYMtyQ1Y7glqRnDLUnNGG5JasZwS1IzhluSmjHcktSM4ZakZgy3JDVjuCWpGcMtSc0YbklqxnBLUjOGW5KaMdyS1IzhlqRmDLckNWO4JamZmeFOcl2Sg0nuXcRAkqQjG7LH/UHgwpHnkCQNNDPcVXU78PUFzCJJGmD7vJ4oyQawAbC6ujqvp5VeEtZ27l7aa++/5uKlvbbGMbc3J6tqV1WtV9X6ysrKvJ5WknQYzyqRpGYMtyQ1M+R0wOuBLwBnJDmQ5Krxx5IkbWXmm5NVdcUiBpEkDeOhEklqxnBLUjOGW5KaMdyS1IzhlqRmDLckNWO4JakZwy1JzRhuSWrGcEtSM4Zbkpox3JLUjOGWpGYMtyQ1Y7glqRnDLUnNGG5JasZwS1IzhluSmjHcktTMoHAnuTDJQ0keTrJz7KEkSVubGe4k24BrgbcDZwJXJDlz7MEkSZsbssd9LvBwVT1SVU8DHwUuHXcsSdJWhoT7NcBXD7l/YPo5SdISbB+wTTb5XD1vo2QD2JjefSrJQy9gnh3AEy/g13Xmmhco71/GqwKu+biQ9x/Tmn986IZDwn0AOO2Q+6cCjx6+UVXtAnYNfeHNJNlTVevH8hzduObjg2s+PixqzUMOlfwL8NokP5HkROBy4KZxx5IkbWXmHndVPZPkV4G/B7YB11XVfaNPJkna1JBDJVTVp4BPjTwLHOOhlqZc8/HBNR8fFrLmVD3vfUZJ0ouYl7xLUjMLD/esy+eT/ECSj00fvzPJ2qJnnLcBa/61JPcnuSfJPyUZfFrQi9nQH5WQ5LIklaT9GQhD1pzk56Zf7/uSfGTRM87bgO/v1SS3Jrl7+j1+0TLmnJck1yU5mOTeLR5Pkj+a/n7ck+ScuQ9RVQv7YPLm5leA04ETgS8BZx62za8AfzK9fTnwsUXOuKQ1vwU4aXr7Xd3XPHTd0+1OBm4H7gDWlz33Ar7WrwXuBn50ev9Vy557AWveBbxrevtMYP+y5z7GNb8ZOAe4d4vHLwI+zeQamDcCd857hkXvcQ+5fP5S4EPT2zcAFyTZ7CKgLmauuapurarvTO/eweRc+e6G/qiE3wF+F/ifRQ43kiFr/mXg2qr6b4CqOrjgGedtyJoLeMX09o+wyXUgnVTV7cDXj7DJpcBf1sQdwClJXj3PGRYd7iGXzz+3TVU9AzwJvHIh043jaH9kwFVM/m/d3cx1JzkbOK2qbl7kYCMa8rV+HfC6JJ9PckeSCxc23TiGrPk3gSuTHGBydtq7FzPa0oz+Y0IGnQ44R0Munx90iX0jg9eT5EpgHfipUSdajCOuO8nLgN8H3rGogRZgyNd6O5PDJT/N5G9W/5zkrKr6xsizjWXImq8APlhVv5fkTcBfTdf8v+OPtxSjN2zRe9xDLp9/bpsk25n81epIfy15sRv0IwOSvBV4H3BJVX13QbONada6TwbOAm5Lsp/JscCbmr9BOfT7+++q6ntV9W/AQ0xC3tWQNV8FfBygqr4AvJzJzzF5qRr0Z/5YLDrcQy6fvwn4xenty4DP1vSIf1Mz1zw9ZPCnTKLd/Zjns4647qp6sqp2VNVaVa0xObZ/SVXtWc64czHk+/uTTN6MJskOJodOHlnolPM1ZM3/AVwAkOQnmYT78YVOuVg3Ab8wPbvkjcCTVfXYXF9hCe/IXgT8K5N3ot83/dxvM/lDC5Mv6t8ADwNfBE5f9rvIC1jzPwJfA/ZNP25a9syLWPdh295G87NKBn6tA3wAuB/4MnD5smdewJrPBD7P5IyTfcDblj3zMa73euAx4HtM9q6vAt4JvPOQr/G109+PL4/xfe2Vk5LUjFdOSlIzhluSmjHcktSM4ZakZgy3JDVjuCWpGcMtSc0Ybklq5v8AYr8iqiCJwSIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tmp.loc[tmp['Solvent.1']=='cyclohexane','Quantum Yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4., 1., 3., 0., 1., 1., 2., 1., 0., 1.]),\n",
       " array([0.001 , 0.0829, 0.1648, 0.2467, 0.3286, 0.4105, 0.4924, 0.5743,\n",
       "        0.6562, 0.7381, 0.82  ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tmp.loc[tmp['Solvent.1']=='methanol','Quantum Yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5., 2., 1., 0., 0., 0., 0., 0., 1., 1.]),\n",
       " array([0.0019 , 0.09871, 0.19552, 0.29233, 0.38914, 0.48595, 0.58276,\n",
       "        0.67957, 0.77638, 0.87319, 0.97   ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tmp.loc[tmp['Solvent.1']=='toluene','Quantum Yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
